* 
* ==> Audit <==
* |------------|--------------------------------------|----------|---------|---------|---------------------|---------------------|
|  Command   |                 Args                 | Profile  |  User   | Version |     Start Time      |      End Time       |
|------------|--------------------------------------|----------|---------|---------|---------------------|---------------------|
| help       |                                      | minikube | T971012 | v1.32.0 | 06 Dec 23 14:11 EST | 06 Dec 23 14:11 EST |
| start      | --driver=qemu                        | minikube | T971012 | v1.32.0 | 06 Dec 23 14:23 EST | 06 Dec 23 14:24 EST |
| addons     | enable ingress                       | minikube | T971012 | v1.32.0 | 08 Dec 23 10:33 EST | 08 Dec 23 10:33 EST |
| addons     | enable kubernettes-dashboard         | minikube | T971012 | v1.32.0 | 08 Dec 23 10:57 EST |                     |
| addons     | enable dashboard                     | minikube | T971012 | v1.32.0 | 08 Dec 23 10:58 EST | 08 Dec 23 10:58 EST |
| service    | mongo-express-service                | minikube | T971012 | v1.32.0 | 10 Dec 23 23:53 EST |                     |
| dashboard  |                                      | minikube | T971012 | v1.32.0 | 12 Dec 23 10:48 EST |                     |
| start      |                                      | minikube | T971012 | v1.32.0 | 09 Mar 25 13:17 EDT |                     |
| start      |                                      | minikube | root    | v1.32.0 | 09 Mar 25 13:19 EDT |                     |
| start      | --driver=none                        | minikube | root    | v1.32.0 | 09 Mar 25 13:21 EDT |                     |
| start      | --driver=qemu2                       | minikube | root    | v1.32.0 | 09 Mar 25 13:22 EDT |                     |
| start      | --driver=qemu2                       | minikube | T971012 | v1.32.0 | 09 Mar 25 13:23 EDT |                     |
| delete     |                                      | minikube | T971012 | v1.32.0 | 09 Mar 25 13:24 EDT | 09 Mar 25 13:24 EDT |
| start      |                                      | minikube | T971012 | v1.32.0 | 09 Mar 25 13:26 EDT | 09 Mar 25 13:26 EDT |
| dashboard  |                                      | minikube | T971012 | v1.32.0 | 09 Mar 25 13:40 EDT |                     |
| stop       |                                      | minikube | T971012 | v1.32.0 | 14 Mar 25 12:46 EDT | 14 Mar 25 12:46 EDT |
| start      | --cpus 6 --memory 8192               | minikube | T971012 | v1.32.0 | 22 Mar 25 14:51 EDT | 22 Mar 25 14:52 EDT |
| stop       |                                      | minikube | T971012 | v1.32.0 | 23 Mar 25 12:21 EDT | 23 Mar 25 12:22 EDT |
| start      | --cpus 6 --memory 8192               | minikube | T971012 | v1.32.0 | 23 Mar 25 15:35 EDT | 23 Mar 25 15:36 EDT |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 14:49 EDT | 25 Mar 25 14:49 EDT |
| docker-env | minikube docker-env                  | minikube | T971012 | v1.32.0 | 25 Mar 25 14:51 EDT | 25 Mar 25 14:51 EDT |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 14:55 EDT | 25 Mar 25 14:55 EDT |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 15:01 EDT | 25 Mar 25 15:01 EDT |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 15:03 EDT | 25 Mar 25 15:03 EDT |
|            | nowshahri/istiocanary:v1        |          |         |         |                     |                     |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 15:03 EDT | 25 Mar 25 15:03 EDT |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 15:04 EDT | 25 Mar 25 15:04 EDT |
| image      | load nignx:latest                    | minikube | T971012 | v1.32.0 | 25 Mar 25 15:14 EDT | 25 Mar 25 15:14 EDT |
| image      | load nginx:latest                    | minikube | T971012 | v1.32.0 | 25 Mar 25 15:14 EDT | 25 Mar 25 15:14 EDT |
| docker-env |                                      | minikube | T971012 | v1.32.0 | 25 Mar 25 15:15 EDT | 25 Mar 25 15:15 EDT |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 15:20 EDT | 25 Mar 25 15:20 EDT |
|            | nowshahri/istiocanary:v1        |          |         |         |                     |                     |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 15:27 EDT | 25 Mar 25 15:27 EDT |
|            | nowshahri/istiocanary:v1        |          |         |         |                     |                     |
| image      | load aputra/myapp-173:v1             | minikube | T971012 | v1.32.0 | 25 Mar 25 15:39 EDT | 25 Mar 25 15:39 EDT |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 15:47 EDT | 25 Mar 25 15:47 EDT |
|            | aputra/myapp-lesson155:v0.1.8        |          |         |         |                     |                     |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 15:51 EDT | 25 Mar 25 15:51 EDT |
|            | aputra/myapp-lesson155:v0.1.1        |          |         |         |                     |                     |
| image      | load                                 | minikube | T971012 | v1.32.0 | 25 Mar 25 18:51 EDT | 25 Mar 25 18:51 EDT |
|            | moduscreate/quarkus-hello-service:v1 |          |         |         |                     |                     |
| stop       |                                      | minikube | T971012 | v1.32.0 | 26 Mar 25 16:57 EDT | 26 Mar 25 16:57 EDT |
| start      |                                      | minikube | T971012 | v1.32.0 | 26 Mar 25 16:58 EDT | 26 Mar 25 16:59 EDT |
| stop       |                                      | minikube | T971012 | v1.32.0 | 27 Mar 25 17:16 EDT | 27 Mar 25 17:17 EDT |
| start      | --cpus 6 --memory 8192               | minikube | T971012 | v1.32.0 | 27 Mar 25 17:19 EDT |                     |
| start      |                                      | minikube | T971012 | v1.32.0 | 27 Mar 25 17:22 EDT | 27 Mar 25 17:22 EDT |
| delete     |                                      | minikube | T971012 | v1.32.0 | 27 Mar 25 17:53 EDT | 27 Mar 25 17:53 EDT |
| start      | --vm-driver=qemu2                    | minikube | T971012 | v1.32.0 | 27 Mar 25 17:56 EDT | 27 Mar 25 17:57 EDT |
| start      |                                      | minikube | T971012 | v1.32.0 | 28 Mar 25 14:37 EDT | 28 Mar 25 14:37 EDT |
| stop       |                                      | minikube | T971012 | v1.32.0 | 28 Mar 25 14:53 EDT | 28 Mar 25 14:53 EDT |
| image      | load                                 | minikube | T971012 | v1.32.0 | 29 Mar 25 13:29 EDT |                     |
|            | docker.io/library/mytestimage:v1     |          |         |         |                     |                     |
| image      | load mytestimage:v1                  | minikube | T971012 | v1.32.0 | 29 Mar 25 13:32 EDT |                     |
| cache      | add mytestimage:v1                   | minikube | T971012 | v1.32.0 | 29 Mar 25 13:40 EDT |                     |
| image      | load mytestimage:v1                  | minikube | T971012 | v1.32.0 | 29 Mar 25 13:42 EDT |                     |
| start      |                                      | minikube | T971012 | v1.32.0 | 29 Mar 25 14:46 EDT | 29 Mar 25 14:47 EDT |
| ip         |                                      | minikube | T971012 | v1.32.0 | 01 Apr 25 19:52 EDT | 01 Apr 25 19:52 EDT |
| ip         |                                      | minikube | T971012 | v1.32.0 | 01 Apr 25 19:58 EDT | 01 Apr 25 19:58 EDT |
| service    | grafana-ext --url                    | minikube | T971012 | v1.32.0 | 01 Apr 25 20:28 EDT |                     |
| stop       |                                      | minikube | T971012 | v1.32.0 | 01 Apr 25 20:30 EDT | 01 Apr 25 20:31 EDT |
| start      | --network=socket_vmnet               | minikube | T971012 | v1.32.0 | 01 Apr 25 20:31 EDT |                     |
| start      |                                      | minikube | T971012 | v1.32.0 | 01 Apr 25 20:41 EDT |                     |
|------------|--------------------------------------|----------|---------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2025/04/01 20:41:52
Running on machine: Yasirs-MBP
Binary: Built with gc go1.21.4 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0401 20:41:52.506995   72742 out.go:296] Setting OutFile to fd 1 ...
I0401 20:41:52.507683   72742 out.go:348] isatty.IsTerminal(1) = true
I0401 20:41:52.507687   72742 out.go:309] Setting ErrFile to fd 2...
I0401 20:41:52.507690   72742 out.go:348] isatty.IsTerminal(2) = true
I0401 20:41:52.508012   72742 root.go:338] Updating PATH: /Users/T971012/.minikube/bin
I0401 20:41:52.510755   72742 out.go:303] Setting JSON to false
I0401 20:41:52.567779   72742 start.go:128] hostinfo: {"hostname":"Yasirs-MBP","uptime":1581149,"bootTime":1741973363,"procs":453,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"14.1.2","kernelVersion":"23.1.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"30e65217-f86b-5d50-ab74-55873e9f6131"}
W0401 20:41:52.568087   72742 start.go:136] gopshost.Virtualization returned error: not implemented yet
I0401 20:41:52.573434   72742 out.go:177] üòÑ  minikube v1.32.0 on Darwin 14.1.2 (arm64)
I0401 20:41:52.582042   72742 notify.go:220] Checking for updates...
I0401 20:41:52.582125   72742 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0401 20:41:52.582860   72742 driver.go:378] Setting default libvirt URI to qemu:///system
I0401 20:41:52.591165   72742 out.go:177] ‚ú®  Using the qemu2 driver based on existing profile
I0401 20:41:52.595130   72742 start.go:298] selected driver: qemu2
I0401 20:41:52.595155   72742 start.go:902] validating driver "qemu2" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:65034 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0401 20:41:52.595197   72742 start.go:913] status for qemu2: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0401 20:41:52.596645   72742 cni.go:84] Creating CNI manager for ""
I0401 20:41:52.596806   72742 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0401 20:41:52.596809   72742 start_flags.go:323] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:65034 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0401 20:41:52.643306   72742 iso.go:125] acquiring lock: {Name:mkc8ab7f924e48b4198a29583c9e5b531c4a8dd7 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0401 20:41:52.651133   72742 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0401 20:41:52.655193   72742 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0401 20:41:52.655213   72742 preload.go:148] Found local preload: /Users/T971012/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-arm64.tar.lz4
I0401 20:41:52.655226   72742 cache.go:56] Caching tarball of preloaded images
I0401 20:41:52.655504   72742 preload.go:174] Found /Users/T971012/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.28.3-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I0401 20:41:52.655513   72742 cache.go:59] Finished verifying existence of preloaded tar for  v1.28.3 on docker
I0401 20:41:52.655735   72742 profile.go:148] Saving config to /Users/T971012/.minikube/profiles/minikube/config.json ...
I0401 20:41:52.657324   72742 start.go:365] acquiring machines lock for minikube: {Name:mk29d72dd80c98d91a0d85c89b2ec43fff8a7685 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0401 20:41:52.657377   72742 start.go:369] acquired machines lock for "minikube" in 39.583¬µs
I0401 20:41:52.657394   72742 start.go:96] Skipping create...Using existing machine configuration
I0401 20:41:52.657408   72742 fix.go:54] fixHost starting: 
I0401 20:41:52.658572   72742 fix.go:102] recreateIfNeeded on minikube: state=Running err=<nil>
W0401 20:41:52.658578   72742 fix.go:128] unexpected machine state, will restart: <nil>
I0401 20:41:52.661260   72742 out.go:177] üèÉ  Updating the running qemu2 "minikube" VM ...
I0401 20:41:52.668166   72742 machine.go:88] provisioning docker machine ...
I0401 20:41:52.668183   72742 buildroot.go:166] provisioning hostname "minikube"
I0401 20:41:52.668406   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:52.669643   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:52.669647   72742 main.go:141] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0401 20:41:52.759689   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: minikube

I0401 20:41:52.759767   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:52.760026   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:52.760033   72742 main.go:141] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0401 20:41:52.841154   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0401 20:41:52.841164   72742 buildroot.go:172] set auth options {CertDir:/Users/T971012/.minikube CaCertPath:/Users/T971012/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/T971012/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/T971012/.minikube/machines/server.pem ServerKeyPath:/Users/T971012/.minikube/machines/server-key.pem ClientKeyPath:/Users/T971012/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/T971012/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/T971012/.minikube}
I0401 20:41:52.841179   72742 buildroot.go:174] setting up certificates
I0401 20:41:52.841185   72742 provision.go:83] configureAuth start
I0401 20:41:52.841189   72742 provision.go:138] copyHostCerts
I0401 20:41:52.841332   72742 exec_runner.go:144] found /Users/T971012/.minikube/cert.pem, removing ...
I0401 20:41:52.841665   72742 exec_runner.go:203] rm: /Users/T971012/.minikube/cert.pem
I0401 20:41:52.842491   72742 exec_runner.go:151] cp: /Users/T971012/.minikube/certs/cert.pem --> /Users/T971012/.minikube/cert.pem (1123 bytes)
I0401 20:41:52.842977   72742 exec_runner.go:144] found /Users/T971012/.minikube/key.pem, removing ...
I0401 20:41:52.842979   72742 exec_runner.go:203] rm: /Users/T971012/.minikube/key.pem
I0401 20:41:52.843639   72742 exec_runner.go:151] cp: /Users/T971012/.minikube/certs/key.pem --> /Users/T971012/.minikube/key.pem (1675 bytes)
I0401 20:41:52.844070   72742 exec_runner.go:144] found /Users/T971012/.minikube/ca.pem, removing ...
I0401 20:41:52.844073   72742 exec_runner.go:203] rm: /Users/T971012/.minikube/ca.pem
I0401 20:41:52.844509   72742 exec_runner.go:151] cp: /Users/T971012/.minikube/certs/ca.pem --> /Users/T971012/.minikube/ca.pem (1082 bytes)
I0401 20:41:52.844937   72742 provision.go:112] generating server cert: /Users/T971012/.minikube/machines/server.pem ca-key=/Users/T971012/.minikube/certs/ca.pem private-key=/Users/T971012/.minikube/certs/ca-key.pem org=T971012.minikube san=[127.0.0.1 localhost localhost 127.0.0.1 minikube minikube]
I0401 20:41:52.948087   72742 provision.go:172] copyRemoteCerts
I0401 20:41:52.948475   72742 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0401 20:41:52.948484   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
I0401 20:41:52.989918   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0401 20:41:52.997861   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1082 bytes)
I0401 20:41:53.006825   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/machines/server.pem --> /etc/docker/server.pem (1208 bytes)
I0401 20:41:53.015967   72742 provision.go:86] duration metric: configureAuth took 174.773709ms
I0401 20:41:53.015976   72742 buildroot.go:189] setting minikube options for container-runtime
I0401 20:41:53.016100   72742 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0401 20:41:53.016146   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:53.016373   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:53.016376   72742 main.go:141] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0401 20:41:53.095102   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: tmpfs

I0401 20:41:53.095106   72742 buildroot.go:70] root file system type: tmpfs
I0401 20:41:53.095159   72742 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0401 20:41:53.095211   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:53.095432   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:53.096153   72742 main.go:141] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0401 20:41:53.175998   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0401 20:41:53.176154   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:53.176473   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:53.176480   72742 main.go:141] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0401 20:41:53.254774   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: 
I0401 20:41:53.254781   72742 machine.go:91] provisioned docker machine in 586.611292ms
I0401 20:41:53.254787   72742 start.go:300] post-start starting for "minikube" (driver="qemu2")
I0401 20:41:53.254792   72742 start.go:329] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0401 20:41:53.254898   72742 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0401 20:41:53.254905   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
I0401 20:41:53.297595   72742 ssh_runner.go:195] Run: cat /etc/os-release
I0401 20:41:53.299734   72742 info.go:137] Remote host: Buildroot 2021.02.12
I0401 20:41:53.299749   72742 filesync.go:126] Scanning /Users/T971012/.minikube/addons for local assets ...
I0401 20:41:53.299845   72742 filesync.go:126] Scanning /Users/T971012/.minikube/files for local assets ...
I0401 20:41:53.299881   72742 start.go:303] post-start completed in 45.090583ms
I0401 20:41:53.299884   72742 fix.go:56] fixHost completed within 642.488375ms
I0401 20:41:53.299929   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:53.300154   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:53.300158   72742 main.go:141] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I0401 20:41:53.380270   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: 1743554584.879029405

I0401 20:41:53.380276   72742 fix.go:206] guest clock: 1743554584.879029405
I0401 20:41:53.380280   72742 fix.go:219] Guest: 2025-04-01 20:43:04.879029405 -0400 EDT Remote: 2025-04-01 20:41:53.299885 -0400 EDT m=+0.950099918 (delta=1m11.579144405s)
I0401 20:41:53.380350   72742 main.go:141] libmachine: Using SSH client type: native
I0401 20:41:53.380590   72742 main.go:141] libmachine: &{{{<nil> 0 [] [] []} docker [0x104446f80] 0x1044496f0 <nil>  [] 0s} localhost 50440 <nil> <nil>}
I0401 20:41:53.380593   72742 main.go:141] libmachine: About to run SSH command:
sudo date -s @1743554513
I0401 20:41:53.461601   72742 main.go:141] libmachine: SSH cmd err, output: <nil>: Wed Apr  2 00:41:53 UTC 2025

I0401 20:41:53.461608   72742 fix.go:226] clock set: Wed Apr  2 00:41:53 UTC 2025
 (err=<nil>)
I0401 20:41:53.461611   72742 start.go:83] releasing machines lock for "minikube", held for 804.23075ms
I0401 20:41:53.461749   72742 ssh_runner.go:195] Run: cat /version.json
I0401 20:41:53.461758   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
I0401 20:41:53.462777   72742 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0401 20:41:53.463518   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
I0401 20:41:53.504658   72742 ssh_runner.go:195] Run: systemctl --version
I0401 20:41:53.587065   72742 ssh_runner.go:195] Run: sh -c "stat /etc/cni/net.d/*loopback.conf*"
W0401 20:41:53.589806   72742 cni.go:209] loopback cni configuration skipped: "/etc/cni/net.d/*loopback.conf*" not found
I0401 20:41:53.589854   72742 ssh_runner.go:195] Run: sudo find /etc/cni/net.d -maxdepth 1 -type f ( ( -name *bridge* -or -name *podman* ) -and -not -name *.mk_disabled ) -printf "%!p(MISSING), " -exec sh -c "sudo mv {} {}.mk_disabled" ;
I0401 20:41:53.594411   72742 cni.go:259] no active bridge cni configs found in "/etc/cni/net.d" - nothing to disable
I0401 20:41:53.594416   72742 start.go:472] detecting cgroup driver to use...
I0401 20:41:53.596169   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///run/containerd/containerd.sock
" | sudo tee /etc/crictl.yaml"
I0401 20:41:53.604200   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)sandbox_image = .*$|\1sandbox_image = "registry.k8s.io/pause:3.9"|' /etc/containerd/config.toml"
I0401 20:41:53.607667   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)restrict_oom_score_adj = .*$|\1restrict_oom_score_adj = false|' /etc/containerd/config.toml"
I0401 20:41:53.611079   72742 containerd.go:145] configuring containerd to use "cgroupfs" as cgroup driver...
I0401 20:41:53.611107   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)SystemdCgroup = .*$|\1SystemdCgroup = false|g' /etc/containerd/config.toml"
I0401 20:41:53.615019   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runtime.v1.linux"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0401 20:41:53.619414   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i '/systemd_cgroup/d' /etc/containerd/config.toml"
I0401 20:41:53.623224   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i 's|"io.containerd.runc.v1"|"io.containerd.runc.v2"|g' /etc/containerd/config.toml"
I0401 20:41:53.627414   72742 ssh_runner.go:195] Run: sh -c "sudo rm -rf /etc/cni/net.mk"
I0401 20:41:53.631860   72742 ssh_runner.go:195] Run: sh -c "sudo sed -i -r 's|^( *)conf_dir = .*$|\1conf_dir = "/etc/cni/net.d"|g' /etc/containerd/config.toml"
I0401 20:41:53.636672   72742 ssh_runner.go:195] Run: sudo sysctl net.bridge.bridge-nf-call-iptables
I0401 20:41:53.640859   72742 ssh_runner.go:195] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
I0401 20:41:53.644677   72742 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0401 20:41:53.754161   72742 ssh_runner.go:195] Run: sudo systemctl restart containerd
I0401 20:41:53.763809   72742 start.go:472] detecting cgroup driver to use...
I0401 20:41:53.763882   72742 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0401 20:41:53.773862   72742 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0401 20:41:53.780247   72742 ssh_runner.go:195] Run: sudo systemctl stop -f containerd
I0401 20:41:53.792053   72742 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0401 20:41:53.798381   72742 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0401 20:41:53.806896   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0401 20:41:53.815581   72742 ssh_runner.go:195] Run: which cri-dockerd
I0401 20:41:53.817310   72742 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/cri-docker.service.d
I0401 20:41:53.821005   72742 ssh_runner.go:362] scp memory --> /etc/systemd/system/cri-docker.service.d/10-cni.conf (189 bytes)
I0401 20:41:53.827877   72742 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0401 20:41:53.936053   72742 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0401 20:41:54.033514   72742 docker.go:560] configuring docker to use "cgroupfs" as cgroup driver...
I0401 20:41:54.033572   72742 ssh_runner.go:362] scp memory --> /etc/docker/daemon.json (130 bytes)
I0401 20:41:54.041815   72742 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0401 20:41:54.141757   72742 ssh_runner.go:195] Run: sudo systemctl restart docker
I0401 20:42:05.458794   72742 ssh_runner.go:235] Completed: sudo systemctl restart docker: (11.31701525s)
I0401 20:42:05.458917   72742 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0401 20:42:05.536974   72742 ssh_runner.go:195] Run: sudo systemctl unmask cri-docker.socket
I0401 20:42:05.639479   72742 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0401 20:42:05.753772   72742 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0401 20:42:05.843965   72742 ssh_runner.go:195] Run: sudo systemctl restart cri-docker.socket
I0401 20:42:05.857236   72742 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0401 20:42:05.961936   72742 ssh_runner.go:195] Run: sudo systemctl restart cri-docker
I0401 20:42:06.005003   72742 start.go:519] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0401 20:42:06.005977   72742 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0401 20:42:06.008763   72742 start.go:540] Will wait 60s for crictl version
I0401 20:42:06.008843   72742 ssh_runner.go:195] Run: which crictl
I0401 20:42:06.011210   72742 ssh_runner.go:195] Run: sudo /usr/bin/crictl version
I0401 20:42:06.043694   72742 start.go:556] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  24.0.7
RuntimeApiVersion:  v1
I0401 20:42:06.043778   72742 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0401 20:42:06.062394   72742 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0401 20:42:06.084719   72742 out.go:204] üê≥  Preparing Kubernetes v1.28.3 on Docker 24.0.7 ...
I0401 20:42:06.085187   72742 ssh_runner.go:195] Run: grep 10.0.2.2	host.minikube.internal$ /etc/hosts
I0401 20:42:06.087269   72742 preload.go:132] Checking if preload exists for k8s version v1.28.3 and runtime docker
I0401 20:42:06.087331   72742 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0401 20:42:06.095583   72742 docker.go:671] Got preloaded images: -- stdout --
nowshahri/istiocanary:v1
nowshahri/mytestimage:gowebapp-v1
grafana/grafana:11.6.0
quay.io/prometheus-operator/prometheus-config-reloader:v0.81.0
quay.io/prometheus/alertmanager:v0.28.1
istio/proxyv2:1.25.0
istio/pilot:1.25.0
quay.io/prometheus/prometheus:v3.2.1
quay.io/prometheus/node-exporter:v1.9.0
curlimages/curl:latest
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0
quay.io/prometheus/pushgateway:v1.11.0
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
adminturneddevops/gowebapi:latest
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0401 20:42:06.095980   72742 docker.go:601] Images already preloaded, skipping extraction
I0401 20:42:06.096207   72742 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0401 20:42:06.107191   72742 docker.go:671] Got preloaded images: -- stdout --
nowshahri/istiocanary:v1
nowshahri/mytestimage:gowebapp-v1
grafana/grafana:11.6.0
quay.io/prometheus-operator/prometheus-config-reloader:v0.81.0
quay.io/prometheus/alertmanager:v0.28.1
istio/proxyv2:1.25.0
istio/pilot:1.25.0
quay.io/prometheus/prometheus:v3.2.1
quay.io/prometheus/node-exporter:v1.9.0
curlimages/curl:latest
registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0
quay.io/prometheus/pushgateway:v1.11.0
registry.k8s.io/kube-scheduler:v1.28.3
registry.k8s.io/kube-apiserver:v1.28.3
registry.k8s.io/kube-controller-manager:v1.28.3
registry.k8s.io/kube-proxy:v1.28.3
registry.k8s.io/etcd:3.5.9-0
registry.k8s.io/coredns/coredns:v1.10.1
registry.k8s.io/pause:3.9
adminturneddevops/gowebapi:latest
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0401 20:42:06.107199   72742 cache_images.go:84] Images are preloaded, skipping loading
I0401 20:42:06.107507   72742 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0401 20:42:06.117088   72742 cni.go:84] Creating CNI manager for ""
I0401 20:42:06.117095   72742 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0401 20:42:06.117552   72742 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0401 20:42:06.117576   72742 kubeadm.go:176] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:10.0.2.15 APIServerPort:8443 KubernetesVersion:v1.28.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "10.0.2.15"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:10.0.2.15 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false KubeletConfigOpts:map[hairpinMode:hairpin-veth runtimeRequestTimeout:15m] PrependCriSocketUnix:true}
I0401 20:42:06.117674   72742 kubeadm.go:181] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.2.15
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: unix:///var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 10.0.2.15
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "10.0.2.15"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.28.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
hairpinMode: hairpin-veth
runtimeRequestTimeout: 15m
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0401 20:42:06.117714   72742 kubeadm.go:976] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.28.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=10.0.2.15

[Install]
 config:
{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0401 20:42:06.117781   72742 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.28.3
I0401 20:42:06.122932   72742 binaries.go:44] Found k8s binaries, skipping transfer
I0401 20:42:06.122993   72742 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0401 20:42:06.126405   72742 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (366 bytes)
I0401 20:42:06.132671   72742 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0401 20:42:06.140152   72742 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2082 bytes)
I0401 20:42:06.148274   72742 ssh_runner.go:195] Run: grep 10.0.2.15	control-plane.minikube.internal$ /etc/hosts
I0401 20:42:06.150597   72742 certs.go:56] Setting up /Users/T971012/.minikube/profiles/minikube for IP: 10.0.2.15
I0401 20:42:06.150656   72742 certs.go:190] acquiring lock for shared ca certs: {Name:mk98ce5648784de18c57a3a668c75fa2d78a82b5 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0401 20:42:06.151177   72742 certs.go:199] skipping minikubeCA CA generation: /Users/T971012/.minikube/ca.key
I0401 20:42:06.151400   72742 certs.go:199] skipping proxyClientCA CA generation: /Users/T971012/.minikube/proxy-client-ca.key
I0401 20:42:06.151665   72742 certs.go:315] skipping minikube-user signed cert generation: /Users/T971012/.minikube/profiles/minikube/client.key
I0401 20:42:06.152065   72742 certs.go:315] skipping minikube signed cert generation: /Users/T971012/.minikube/profiles/minikube/apiserver.key.49504c3e
I0401 20:42:06.152352   72742 certs.go:315] skipping aggregator signed cert generation: /Users/T971012/.minikube/profiles/minikube/proxy-client.key
I0401 20:42:06.152768   72742 certs.go:437] found cert: /Users/T971012/.minikube/certs/Users/T971012/.minikube/certs/ca-key.pem (1675 bytes)
I0401 20:42:06.152833   72742 certs.go:437] found cert: /Users/T971012/.minikube/certs/Users/T971012/.minikube/certs/ca.pem (1082 bytes)
I0401 20:42:06.152992   72742 certs.go:437] found cert: /Users/T971012/.minikube/certs/Users/T971012/.minikube/certs/cert.pem (1123 bytes)
I0401 20:42:06.153077   72742 certs.go:437] found cert: /Users/T971012/.minikube/certs/Users/T971012/.minikube/certs/key.pem (1675 bytes)
I0401 20:42:06.153642   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0401 20:42:06.162313   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0401 20:42:06.170909   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0401 20:42:06.181499   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0401 20:42:06.191091   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0401 20:42:06.203504   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0401 20:42:06.212958   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0401 20:42:06.225019   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1675 bytes)
I0401 20:42:06.233975   72742 ssh_runner.go:362] scp /Users/T971012/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0401 20:42:06.246395   72742 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0401 20:42:06.253852   72742 ssh_runner.go:195] Run: openssl version
I0401 20:42:06.257080   72742 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0401 20:42:06.262961   72742 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0401 20:42:06.264661   72742 certs.go:480] hashing: -rw-r--r-- 1 root root 1111 Dec  6  2023 /usr/share/ca-certificates/minikubeCA.pem
I0401 20:42:06.264701   72742 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0401 20:42:06.266659   72742 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0401 20:42:06.271750   72742 ssh_runner.go:195] Run: ls /var/lib/minikube/certs/etcd
I0401 20:42:06.273630   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-etcd-client.crt -checkend 86400
I0401 20:42:06.277278   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/apiserver-kubelet-client.crt -checkend 86400
I0401 20:42:06.280744   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/server.crt -checkend 86400
I0401 20:42:06.283163   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/healthcheck-client.crt -checkend 86400
I0401 20:42:06.286014   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/etcd/peer.crt -checkend 86400
I0401 20:42:06.288260   72742 ssh_runner.go:195] Run: openssl x509 -noout -in /var/lib/minikube/certs/front-proxy-client.crt -checkend 86400
I0401 20:42:06.290576   72742 kubeadm.go:404] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.32.1-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.42@sha256:d35ac07dfda971cabee05e0deca8aeac772f885a5348e1a0c0b0a36db20fcfc0 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:65034 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.28.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath: SocketVMnetPath: StaticIP: SSHAuthSock: SSHAgentPID:0 AutoPauseInterval:1m0s GPUs:}
I0401 20:42:06.290624   72742 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0401 20:42:06.303539   72742 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0401 20:42:06.308059   72742 host.go:66] Checking if "minikube" exists ...
I0401 20:42:06.309179   72742 main.go:141] libmachine: Using SSH client type: external
I0401 20:42:06.309195   72742 main.go:141] libmachine: Using SSH private key: /Users/T971012/.minikube/machines/minikube/id_rsa (-rw-------)
I0401 20:42:06.309209   72742 main.go:141] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/T971012/.minikube/machines/minikube/id_rsa -p 50440] /usr/bin/ssh <nil>}
I0401 20:42:06.309234   72742 main.go:141] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/T971012/.minikube/machines/minikube/id_rsa -p 50440 -f -NTL 65034:localhost:8443
I0401 20:42:06.371893   72742 kubeadm.go:419] found existing configuration files, will attempt cluster restart
I0401 20:42:06.372188   72742 kubeadm.go:636] restartCluster start
I0401 20:42:06.372387   72742 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0401 20:42:06.376094   72742 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0401 20:42:06.377273   72742 kubeconfig.go:92] found "minikube" server: "https://10.0.2.15:8443"
I0401 20:42:06.383061   72742 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0401 20:42:06.387459   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:06.387508   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:06.391836   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:06.391849   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:06.391907   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:06.396043   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:06.896736   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:06.897138   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:06.906106   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:07.396597   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:07.396861   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:07.406008   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:07.897149   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:07.897458   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:07.906430   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:08.397282   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:08.397560   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:08.405856   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:08.896567   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:08.896794   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:08.904766   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:09.397203   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:09.397385   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:09.406335   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:09.897420   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:09.897706   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:09.908437   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:10.396240   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:10.396466   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:10.405362   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:10.896910   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:10.897170   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:10.904994   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:11.397170   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:11.397423   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:11.414061   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:11.897126   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:11.897289   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:11.913382   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:12.397129   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:12.397256   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0401 20:42:12.404292   72742 api_server.go:170] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0401 20:42:12.897106   72742 api_server.go:166] Checking apiserver status ...
I0401 20:42:12.897189   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0401 20:42:12.912503   72742 ssh_runner.go:195] Run: sudo egrep ^[0-9]+:freezer: /proc/23570/cgroup
I0401 20:42:12.915789   72742 api_server.go:182] apiserver freezer: "3:freezer:/kubepods/burstable/pod842672fed952e0ab68deac178344590a/d6ffe70d89ca32271b523db48561cbf347ae7d531b99517f96ec60845f998109"
I0401 20:42:12.915855   72742 ssh_runner.go:195] Run: sudo cat /sys/fs/cgroup/freezer/kubepods/burstable/pod842672fed952e0ab68deac178344590a/d6ffe70d89ca32271b523db48561cbf347ae7d531b99517f96ec60845f998109/freezer.state
I0401 20:42:12.922047   72742 api_server.go:204] freezer state: "THAWED"
I0401 20:42:12.922287   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:17.923583   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:17.923627   72742 retry.go:31] will retry after 302.750208ms: state is "Stopped"
I0401 20:42:18.227436   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:23.228729   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:23.228751   72742 retry.go:31] will retry after 376.976802ms: state is "Stopped"
I0401 20:42:23.606785   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:28.607180   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:28.607230   72742 kubeadm.go:611] needs reconfigure: apiserver error: context deadline exceeded
I0401 20:42:28.607236   72742 kubeadm.go:1128] stopping kube-system containers ...
I0401 20:42:28.607327   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0401 20:42:28.619547   72742 docker.go:469] Stopping containers: [c94b3ae97d6c 32928a6bdc01 421c7c96a3f0 bbecac00b816 5bdab12a4437 60924a430bbb d6ffe70d89ca f239a43ab556 dd0dd60e0260 3cb3f0938bc1 44568598cbeb ddd40d575910 47a2937b9166 07f14045e130 eb08c816ff90 de77b70b4921 a9457931e351 609aa0c4fcc5 ee4e1588c1c0 e43e6a43cae3 57003f5cd171 13893e7ba313 20b70f5baf25 25d77132016e be02e9da10fb af8f6532f37f 0bb4059c6c65 78993043375d 76f3ca01c14b 811d58927e05 2f5ccde4717d baad532ce19a]
I0401 20:42:28.619614   72742 ssh_runner.go:195] Run: docker stop c94b3ae97d6c 32928a6bdc01 421c7c96a3f0 bbecac00b816 5bdab12a4437 60924a430bbb d6ffe70d89ca f239a43ab556 dd0dd60e0260 3cb3f0938bc1 44568598cbeb ddd40d575910 47a2937b9166 07f14045e130 eb08c816ff90 de77b70b4921 a9457931e351 609aa0c4fcc5 ee4e1588c1c0 e43e6a43cae3 57003f5cd171 13893e7ba313 20b70f5baf25 25d77132016e be02e9da10fb af8f6532f37f 0bb4059c6c65 78993043375d 76f3ca01c14b 811d58927e05 2f5ccde4717d baad532ce19a
I0401 20:42:33.755790   72742 ssh_runner.go:235] Completed: docker stop c94b3ae97d6c 32928a6bdc01 421c7c96a3f0 bbecac00b816 5bdab12a4437 60924a430bbb d6ffe70d89ca f239a43ab556 dd0dd60e0260 3cb3f0938bc1 44568598cbeb ddd40d575910 47a2937b9166 07f14045e130 eb08c816ff90 de77b70b4921 a9457931e351 609aa0c4fcc5 ee4e1588c1c0 e43e6a43cae3 57003f5cd171 13893e7ba313 20b70f5baf25 25d77132016e be02e9da10fb af8f6532f37f 0bb4059c6c65 78993043375d 76f3ca01c14b 811d58927e05 2f5ccde4717d baad532ce19a: (5.136156625s)
I0401 20:42:33.756097   72742 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0401 20:42:33.842906   72742 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0401 20:42:33.848120   72742 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5643 Apr  2 00:37 /etc/kubernetes/admin.conf
-rw------- 1 root root 5649 Apr  2 00:37 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 1971 Apr  2 00:37 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5597 Apr  2 00:37 /etc/kubernetes/scheduler.conf

I0401 20:42:33.848178   72742 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0401 20:42:33.852198   72742 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0401 20:42:33.856077   72742 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0401 20:42:33.861079   72742 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I0401 20:42:33.861113   72742 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0401 20:42:33.866831   72742 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0401 20:42:33.871492   72742 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I0401 20:42:33.871563   72742 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0401 20:42:33.875868   72742 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0401 20:42:33.881049   72742 kubeadm.go:713] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0401 20:42:33.881053   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0401 20:42:33.924257   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0401 20:42:34.578686   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0401 20:42:34.724074   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0401 20:42:34.764207   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0401 20:42:34.807314   72742 api_server.go:52] waiting for apiserver process to appear ...
I0401 20:42:34.807420   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0401 20:42:34.814430   72742 api_server.go:72] duration metric: took 7.119166ms to wait for apiserver process to appear ...
I0401 20:42:34.814437   72742 api_server.go:88] waiting for apiserver healthz status ...
I0401 20:42:34.814444   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:39.815830   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:39.815870   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:44.817383   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:45.318010   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:50.318550   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:50.318565   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:42:55.319122   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:42:55.319138   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:00.319449   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:00.319483   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:05.319981   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:05.320020   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:10.321497   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:10.321539   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:15.322054   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:15.322075   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:20.322818   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:20.322834   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:25.323904   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:25.323918   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:30.324938   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:30.324951   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:35.326190   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:35.326422   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:43:35.335571   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:43:35.335654   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:43:35.344185   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:43:35.344260   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:43:35.351999   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:43:35.352085   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:43:35.360087   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:43:35.360122   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:43:35.368061   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:43:35.368125   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:43:35.376226   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:43:35.376271   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:43:35.383547   72742 logs.go:284] 0 containers: []
W0401 20:43:35.383561   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:43:35.383625   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:43:35.400212   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:43:35.400222   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:43:35.400225   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:43:35.408987   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:43:35.408990   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:43:35.440265   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:43:35.440269   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:43:35.448056   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:43:35.448069   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:43:35.456554   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:43:35.456558   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:43:35.468639   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:43:35.468642   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:43:35.481988   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:43:35.481997   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:43:35.499923   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:43:35.499930   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:43:35.508195   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:43:35.508198   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:43:35.518847   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:43:35.518849   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:43:35.535360   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:43:35.535371   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:43:35.552034   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:43:35.552036   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:43:35.558901   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:43:35.558905   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:43:35.570755   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:43:35.570758   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:43:35.578743   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:43:35.578753   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:43:35.589598   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:43:35.589603   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:43:35.635251   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:43:35.635266   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:43:35.702439   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:43:35.702444   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:43:35.713827   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:43:35.713831   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:43:35.727059   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:43:35.727063   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:43:35.739785   72742 logs.go:123] Gathering logs for container status ...
I0401 20:43:35.739790   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:43:38.270388   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:43.272713   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:43.272883   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:43:43.287930   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:43:43.288012   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:43:43.295205   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:43:43.295260   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:43:43.302411   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:43:43.302440   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:43:43.313372   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:43:43.313399   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:43:43.319990   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:43:43.320017   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:43:43.329071   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:43:43.329142   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:43:43.338124   72742 logs.go:284] 0 containers: []
W0401 20:43:43.338129   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:43:43.338162   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:43:43.346170   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:43:43.346195   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:43:43.346202   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:43:43.363744   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:43:43.363753   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:43:43.392140   72742 logs.go:123] Gathering logs for container status ...
I0401 20:43:43.392146   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:43:43.427531   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:43:43.427538   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:43:43.437961   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:43:43.437965   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:43:43.452606   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:43:43.452609   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:43:43.466389   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:43:43.466395   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:43:43.475333   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:43:43.475337   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:43:43.490784   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:43:43.490788   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:43:43.534397   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:43:43.534404   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:43:43.541700   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:43:43.541703   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:43:43.550212   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:43:43.550215   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:43:43.604712   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:43:43.604722   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:43:43.614383   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:43:43.614386   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:43:43.624964   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:43:43.624969   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:43:43.643813   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:43:43.643823   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:43:43.656774   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:43:43.656781   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:43:43.672631   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:43:43.672646   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:43:43.684686   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:43:43.684703   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:43:43.698376   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:43:43.698381   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:43:43.711459   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:43:43.711470   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:43:46.221136   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:51.222485   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:51.222629   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:43:51.231114   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:43:51.231201   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:43:51.240948   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:43:51.240987   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:43:51.249393   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:43:51.249457   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:43:51.262128   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:43:51.262211   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:43:51.271518   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:43:51.271619   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:43:51.280215   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:43:51.280264   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:43:51.288004   72742 logs.go:284] 0 containers: []
W0401 20:43:51.288021   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:43:51.288089   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:43:51.297397   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:43:51.297406   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:43:51.297409   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:43:51.312535   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:43:51.312542   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:43:51.329128   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:43:51.329134   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:43:51.346317   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:43:51.346323   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:43:51.380641   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:43:51.380650   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:43:51.441561   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:43:51.441570   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:43:51.451658   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:43:51.451665   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:43:51.465299   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:43:51.465304   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:43:51.476930   72742 logs.go:123] Gathering logs for container status ...
I0401 20:43:51.476933   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:43:51.511608   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:43:51.511615   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:43:51.528690   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:43:51.528697   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:43:51.541014   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:43:51.541019   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:43:51.550365   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:43:51.550369   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:43:51.561940   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:43:51.561947   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:43:51.571404   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:43:51.571410   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:43:51.589553   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:43:51.589557   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:43:51.605843   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:43:51.605896   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:43:51.617293   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:43:51.617300   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:43:51.630803   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:43:51.630816   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:43:51.671199   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:43:51.671205   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:43:51.678679   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:43:51.678682   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:43:54.192158   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:43:59.193476   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:43:59.193620   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:43:59.205010   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:43:59.205059   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:43:59.215484   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:43:59.215531   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:43:59.223621   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:43:59.223714   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:43:59.231103   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:43:59.231131   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:43:59.238092   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:43:59.238120   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:43:59.245364   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:43:59.245453   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:43:59.252447   72742 logs.go:284] 0 containers: []
W0401 20:43:59.252451   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:43:59.252526   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:43:59.264041   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:43:59.264047   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:43:59.264050   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:43:59.272414   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:43:59.272418   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:43:59.282007   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:43:59.282014   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:43:59.311149   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:43:59.311153   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:43:59.320652   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:43:59.320654   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:43:59.328220   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:43:59.328223   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:43:59.344019   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:43:59.344023   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:43:59.354849   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:43:59.354852   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:43:59.366876   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:43:59.366880   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:43:59.379875   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:43:59.379879   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:43:59.388688   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:43:59.388691   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:43:59.402908   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:43:59.402911   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:43:59.445365   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:43:59.445372   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:43:59.503786   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:43:59.503794   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:43:59.522185   72742 logs.go:123] Gathering logs for container status ...
I0401 20:43:59.522189   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:43:59.550155   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:43:59.550159   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:43:59.559078   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:43:59.559081   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:43:59.565711   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:43:59.565714   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:43:59.577145   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:43:59.577147   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:43:59.586094   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:43:59.586100   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:43:59.594313   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:43:59.594321   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:02.111964   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:07.113390   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:07.113522   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:07.121520   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:07.121567   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:07.129764   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:07.129793   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:07.136403   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:07.136484   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:07.143322   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:07.143429   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:07.149985   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:07.150042   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:07.157701   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:07.157791   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:07.169566   72742 logs.go:284] 0 containers: []
W0401 20:44:07.169578   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:07.169632   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:07.179716   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:07.179725   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:07.179729   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:07.193308   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:07.193313   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:07.203947   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:07.203951   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:07.218963   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:07.218966   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:07.236188   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:07.236191   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:07.247242   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:07.247245   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:07.255744   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:07.255747   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:07.308773   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:07.308779   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:07.317224   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:07.317228   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:07.326250   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:07.326258   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:07.342558   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:07.342562   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:07.359488   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:07.359493   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:07.378370   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:07.378373   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:07.387001   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:07.387004   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:07.400814   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:07.400817   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:07.430458   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:07.430462   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:07.442876   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:07.442879   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:07.448895   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:07.448904   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:07.462276   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:07.462298   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:07.470944   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:07.470949   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:07.505948   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:07.505957   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:10.051722   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:15.053386   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:15.053544   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:15.062905   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:15.062969   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:15.070811   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:15.070869   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:15.078247   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:15.078276   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:15.086299   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:15.086406   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:15.094918   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:15.094980   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:15.102365   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:15.102437   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:15.110430   72742 logs.go:284] 0 containers: []
W0401 20:44:15.110435   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:15.110473   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:15.118499   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:15.118537   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:15.118540   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:15.177944   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:15.177952   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:15.186366   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:15.186373   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:15.202692   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:15.202696   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:15.215021   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:15.215029   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:15.241705   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:15.241709   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:15.255409   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:15.255415   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:15.271242   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:15.271245   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:15.280492   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:15.280495   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:15.312490   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:15.312499   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:15.356039   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:15.356070   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:15.363306   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:15.363312   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:15.377643   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:15.377653   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:15.386864   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:15.386868   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:15.398046   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:15.398049   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:15.406416   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:15.406419   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:15.414578   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:15.414581   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:15.426982   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:15.426985   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:15.467271   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:15.467283   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:15.482623   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:15.482630   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:15.501186   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:15.501194   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:18.018236   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:23.019575   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:23.019724   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:23.027719   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:23.027801   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:23.034718   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:23.034768   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:23.042136   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:23.042159   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:23.049237   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:23.049272   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:23.056302   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:23.056401   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:23.063176   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:23.063199   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:23.074275   72742 logs.go:284] 0 containers: []
W0401 20:44:23.074281   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:23.074335   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:23.081673   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:23.081681   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:23.081704   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:23.110662   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:23.110669   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:23.120061   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:23.120064   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:23.128794   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:23.128801   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:23.136924   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:23.136944   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:23.150401   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:23.150404   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:23.158594   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:23.158597   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:23.164652   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:23.164660   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:23.175535   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:23.175542   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:23.188799   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:23.188807   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:23.197069   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:23.197078   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:23.213019   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:23.213025   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:23.221842   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:23.221845   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:23.230607   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:23.230610   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:23.269779   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:23.269784   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:23.285417   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:23.285420   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:23.293969   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:23.293978   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:23.308819   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:23.308822   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:23.340667   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:23.340674   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:23.392990   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:23.392995   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:23.409639   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:23.409650   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:25.922837   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:30.923353   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:30.923441   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:30.931654   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:30.931738   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:30.938186   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:30.938222   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:30.949678   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:30.949782   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:30.956804   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:30.956839   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:30.962382   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:30.962401   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:30.969257   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:30.969330   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:30.976404   72742 logs.go:284] 0 containers: []
W0401 20:44:30.976410   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:30.976452   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:30.985917   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:30.985931   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:30.985935   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:30.996244   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:30.996248   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:31.006522   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:31.006525   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:31.014887   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:31.014894   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:31.033131   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:31.033144   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:31.046626   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:31.046629   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:31.073052   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:31.073055   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:31.116020   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:31.116027   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:31.121831   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:31.121839   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:31.129825   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:31.129831   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:31.147940   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:31.147952   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:31.159578   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:31.159588   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:31.167583   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:31.167590   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:31.182714   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:31.182723   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:31.191766   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:31.191774   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:31.266010   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:31.266024   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:31.279925   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:31.279942   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:31.297058   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:31.297066   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:31.306258   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:31.306265   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:31.314411   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:31.314415   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:31.322629   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:31.322633   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:33.851841   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:38.853288   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:38.853435   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:38.863226   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:38.863253   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:38.871365   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:38.871449   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:38.887002   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:38.887038   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:38.895966   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:38.896026   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:38.904693   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:38.904731   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:38.914931   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:38.915002   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:38.923401   72742 logs.go:284] 0 containers: []
W0401 20:44:38.923407   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:38.923495   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:38.933244   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:38.933288   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:38.933299   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:38.980090   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:38.980105   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:39.001440   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:39.001470   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:39.009868   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:39.009873   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:39.025812   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:39.025815   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:39.034399   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:39.034421   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:39.063611   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:39.063614   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:39.077025   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:39.077029   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:39.092713   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:39.092719   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:39.109350   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:39.109353   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:39.118408   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:39.118411   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:39.126150   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:39.126154   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:39.132997   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:39.133008   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:39.146772   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:39.146775   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:39.159444   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:39.159449   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:39.169322   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:39.169332   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:39.178270   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:39.178275   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:39.193719   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:39.193725   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:39.225804   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:39.225810   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:39.289539   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:39.289547   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:39.300974   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:39.300977   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:41.817462   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:46.818518   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:46.818589   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:46.834030   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:46.834108   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:46.847650   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:46.847763   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:46.858604   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:46.858690   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:46.871519   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:46.871581   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:46.879995   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:46.880061   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:46.888513   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:46.888657   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:46.896413   72742 logs.go:284] 0 containers: []
W0401 20:44:46.896428   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:46.896507   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:46.904292   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:46.904304   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:46.904309   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:46.916392   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:46.916401   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:46.934209   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:46.934218   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:46.951915   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:46.951924   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:46.965718   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:46.965727   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:46.978264   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:46.978273   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:46.988000   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:46.988009   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:47.056179   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:47.056189   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:47.069287   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:47.069296   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:47.081840   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:47.081850   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:47.090532   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:47.090542   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:47.100939   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:47.100947   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:47.116463   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:47.116473   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:47.147567   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:47.147578   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:47.193126   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:47.193160   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:47.202347   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:47.202356   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:47.210743   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:47.210755   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:47.239193   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:47.239202   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:47.247843   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:47.247851   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:47.260581   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:47.260589   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:47.279470   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:47.279479   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:49.792154   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:44:54.793447   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:44:54.793562   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:44:54.803862   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:44:54.803913   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:44:54.812162   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:44:54.812227   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:44:54.819756   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:44:54.819819   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:44:54.826421   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:44:54.826449   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:44:54.833278   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:44:54.833352   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:44:54.842644   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:44:54.842666   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:44:54.849724   72742 logs.go:284] 0 containers: []
W0401 20:44:54.849726   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:44:54.849748   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:44:54.857051   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:44:54.857063   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:44:54.857066   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:44:54.917252   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:44:54.917258   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:44:54.927074   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:44:54.927078   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:44:54.941059   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:44:54.941062   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:44:54.954665   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:44:54.954667   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:44:54.987850   72742 logs.go:123] Gathering logs for container status ...
I0401 20:44:54.987857   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:44:55.014935   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:44:55.014943   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:44:55.057835   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:44:55.057840   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:44:55.070732   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:44:55.070737   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:44:55.078979   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:44:55.078983   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:44:55.098252   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:44:55.098257   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:44:55.111136   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:44:55.111139   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:44:55.122229   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:44:55.122233   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:44:55.135771   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:44:55.135773   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:44:55.148292   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:44:55.148294   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:44:55.156151   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:44:55.156156   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:44:55.164194   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:44:55.164198   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:44:55.170215   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:44:55.170218   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:44:55.181482   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:44:55.181484   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:44:55.197094   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:44:55.197097   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:44:55.211199   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:44:55.211202   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:44:57.721019   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:02.722278   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:02.722441   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:02.730807   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:02.730874   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:02.737651   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:02.737718   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:02.746700   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:02.746761   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:02.753858   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:02.753886   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:02.761252   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:02.761323   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:02.768542   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:02.768590   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:02.775562   72742 logs.go:284] 0 containers: []
W0401 20:45:02.775568   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:02.775621   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:02.782490   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:02.782500   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:02.782504   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:02.794249   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:02.794255   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:02.805555   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:02.805557   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:02.812921   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:02.812924   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:02.845748   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:02.845753   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:02.852565   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:02.852568   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:02.860847   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:02.860861   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:02.888536   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:02.888551   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:02.949431   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:02.949439   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:02.963648   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:02.963652   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:02.979473   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:02.979481   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:02.987925   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:02.987934   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:03.003489   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:03.003492   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:03.022132   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:03.022138   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:03.072247   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:03.072256   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:03.083899   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:03.083905   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:03.093035   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:03.093042   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:03.102558   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:03.102565   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:03.111404   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:03.111408   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:03.124228   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:03.124233   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:03.137688   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:03.137693   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:05.647218   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:10.648578   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:10.648798   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:10.666230   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:10.666290   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:10.674902   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:10.674936   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:10.682073   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:10.682127   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:10.694030   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:10.694058   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:10.700515   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:10.700550   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:10.707746   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:10.707774   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:10.714871   72742 logs.go:284] 0 containers: []
W0401 20:45:10.714873   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:10.714891   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:10.722181   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:10.722188   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:10.722192   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:10.736799   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:10.736802   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:10.767885   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:10.767889   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:10.784907   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:10.784913   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:10.798221   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:10.798225   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:10.810050   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:10.810057   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:10.822601   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:10.822605   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:10.830915   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:10.830922   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:10.876359   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:10.876390   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:10.887800   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:10.887804   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:10.898977   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:10.898981   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:10.906784   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:10.906786   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:10.919367   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:10.919374   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:10.935122   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:10.935124   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:10.941413   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:10.941415   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:10.949327   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:10.949329   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:10.958443   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:10.958446   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:10.967219   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:10.967221   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:10.980469   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:10.980472   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:10.988672   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:10.988675   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:11.018023   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:11.018026   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:13.577749   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:18.579014   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:18.579197   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:18.587414   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:18.587441   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:18.594974   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:18.595040   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:18.602689   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:18.602730   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:18.610553   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:18.610648   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:18.618720   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:18.618763   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:18.626470   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:18.626529   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:18.633358   72742 logs.go:284] 0 containers: []
W0401 20:45:18.633363   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:18.633427   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:18.640512   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:18.640519   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:18.640522   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:18.654292   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:18.654295   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:18.664421   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:18.664427   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:18.684426   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:18.684434   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:18.693706   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:18.693717   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:18.780956   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:18.780963   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:18.799775   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:18.799787   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:18.807824   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:18.807832   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:18.818314   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:18.818323   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:18.833276   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:18.833285   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:18.898971   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:18.898985   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:18.912497   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:18.912503   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:18.924074   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:18.924078   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:18.961532   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:18.961540   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:18.974506   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:18.974512   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:18.990020   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:18.990024   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:19.020803   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:19.020809   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:19.028902   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:19.028907   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:19.039791   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:19.039794   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:19.046907   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:19.046912   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:19.062909   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:19.062912   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:21.571563   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:26.572877   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:26.573045   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:26.582572   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:26.582658   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:26.591623   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:26.591661   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:26.599106   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:26.599220   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:26.607449   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:26.607551   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:26.616625   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:26.616690   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:26.625239   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:26.625311   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:26.633145   72742 logs.go:284] 0 containers: []
W0401 20:45:26.633150   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:26.633180   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:26.643021   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:26.643029   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:26.643033   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:26.655402   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:26.655407   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:26.667957   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:26.667961   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:26.682351   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:26.682365   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:26.691665   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:26.691671   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:26.708310   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:26.708315   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:26.742783   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:26.742800   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:26.773276   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:26.773283   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:26.781130   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:26.781134   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:26.794490   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:26.794494   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:26.805187   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:26.805192   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:26.815860   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:26.815863   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:26.831933   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:26.831940   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:26.843187   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:26.843192   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:26.858720   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:26.858724   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:26.872127   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:26.872133   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:26.881844   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:26.881850   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:26.891140   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:26.891145   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:26.933111   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:26.933116   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:27.013135   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:27.013143   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:27.027043   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:27.027050   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:29.538683   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:34.540104   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:34.540245   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:34.549049   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:34.549116   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:34.557886   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:34.557979   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:34.568969   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:34.569041   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:34.578248   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:34.578307   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:34.586346   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:34.586393   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:34.594767   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:34.594840   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:34.608451   72742 logs.go:284] 0 containers: []
W0401 20:45:34.608461   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:34.608533   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:34.617879   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:34.617919   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:34.617927   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:34.627260   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:34.627266   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:34.637082   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:34.637091   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:34.649775   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:34.649780   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:34.660500   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:34.660507   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:34.672053   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:34.672058   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:34.680543   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:34.680546   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:34.688887   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:34.688902   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:34.704378   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:34.704382   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:34.736279   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:34.736283   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:34.791161   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:34.791166   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:34.807075   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:34.807080   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:34.822150   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:34.822158   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:34.854344   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:34.854348   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:34.896848   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:34.896861   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:34.910150   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:34.910155   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:34.925968   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:34.925972   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:34.933754   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:34.933758   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:34.940611   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:34.940613   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:34.952190   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:34.952195   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:34.962177   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:34.962181   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:37.481521   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:42.482921   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:42.483034   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:42.490928   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:42.490979   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:42.502727   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:42.502796   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:42.510122   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:42.513201   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:42.528025   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:42.528074   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:42.535358   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:42.535416   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:42.549690   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:42.549776   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:42.557148   72742 logs.go:284] 0 containers: []
W0401 20:45:42.557154   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:42.557206   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:42.564781   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:42.564787   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:42.564791   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:42.570885   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:42.570889   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:42.583486   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:42.583489   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:42.593408   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:42.593411   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:42.604260   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:42.604262   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:42.624634   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:42.624641   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:42.635005   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:42.635009   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:42.643633   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:42.643637   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:42.661415   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:42.661417   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:42.670042   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:42.670045   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:42.679303   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:42.679311   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:42.686638   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:42.686647   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:42.695385   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:42.695389   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:42.704263   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:42.704267   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:42.712255   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:42.712258   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:42.739431   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:42.739434   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:42.779111   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:42.779116   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:42.832017   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:42.832021   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:42.842792   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:42.842795   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:42.855760   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:42.855763   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:42.871737   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:42.871743   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:45.403651   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:50.405070   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:50.405213   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:50.415041   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:50.415187   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:50.423987   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:50.424087   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:50.433706   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:50.433783   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:50.444425   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:50.444508   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:50.456503   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:50.456863   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:50.467286   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:50.467337   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:50.478356   72742 logs.go:284] 0 containers: []
W0401 20:45:50.478366   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:50.478418   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:50.489447   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:50.489463   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:50.489469   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:50.497492   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:50.497501   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:50.507559   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:50.507568   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:50.532258   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:50.532269   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:50.579946   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:50.579956   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:50.593560   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:50.593567   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:50.605887   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:50.605890   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:50.617498   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:50.617500   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:50.625587   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:50.625592   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:50.639763   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:50.639768   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:50.651748   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:50.651751   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:50.673448   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:50.673453   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:50.683274   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:50.683277   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:50.697156   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:50.697162   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:50.728188   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:50.728193   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:45:50.757855   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:50.757861   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:50.767594   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:50.767611   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:50.833604   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:50.833613   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:50.851292   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:50.851298   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:50.864656   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:50.864666   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:50.879543   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:50.879546   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:53.394831   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:45:58.396386   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:45:58.396481   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:45:58.407451   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:45:58.407484   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:45:58.415517   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:45:58.415594   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:45:58.425163   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:45:58.425247   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:45:58.433573   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:45:58.433610   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:45:58.442162   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:45:58.442202   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:45:58.450295   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:45:58.450316   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:45:58.462102   72742 logs.go:284] 0 containers: []
W0401 20:45:58.462110   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:45:58.462180   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:45:58.471304   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:45:58.471317   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:45:58.471321   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:45:58.486676   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:45:58.486682   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:45:58.493365   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:45:58.493369   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:45:58.509891   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:45:58.509895   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:45:58.524744   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:45:58.524749   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:45:58.550532   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:45:58.550536   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:45:58.559087   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:45:58.559104   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:45:58.572355   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:45:58.572362   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:45:58.592035   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:45:58.592039   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:45:58.601869   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:45:58.601876   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:45:58.613277   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:45:58.613282   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:45:58.626258   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:45:58.626265   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:45:58.635426   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:45:58.635432   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:45:58.647535   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:45:58.647541   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:45:58.661170   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:45:58.661174   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:45:58.670008   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:45:58.670015   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:45:58.683759   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:45:58.683764   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:45:58.692829   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:45:58.692832   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:45:58.728204   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:45:58.728214   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:45:58.768497   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:45:58.768502   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:45:58.835096   72742 logs.go:123] Gathering logs for container status ...
I0401 20:45:58.835105   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:46:01.369707   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:46:06.371064   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:46:06.371212   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:46:06.380141   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:46:06.380218   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:46:06.388492   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:46:06.388552   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:46:06.404998   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:46:06.405063   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:46:06.413661   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:46:06.413696   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:46:06.432288   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:46:06.432317   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:46:06.441452   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:46:06.441503   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:46:06.449815   72742 logs.go:284] 0 containers: []
W0401 20:46:06.449818   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:46:06.449856   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:46:06.461737   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:46:06.461749   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:46:06.461753   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:46:06.474194   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:46:06.474202   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:46:06.486541   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:46:06.486547   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:46:06.498668   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:46:06.498678   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:46:06.508001   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:46:06.508007   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:46:06.521214   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:46:06.521219   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:46:06.532395   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:46:06.532399   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:46:06.541399   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:46:06.541425   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:46:06.549239   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:46:06.549242   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:46:06.562979   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:46:06.562982   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:46:06.607280   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:46:06.607285   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:46:06.614679   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:46:06.614684   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:46:06.628466   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:46:06.628474   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:46:06.640189   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:46:06.640193   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:46:06.660161   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:46:06.660166   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:46:06.673831   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:46:06.673847   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:46:06.706050   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:46:06.706056   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:46:06.717668   72742 logs.go:123] Gathering logs for container status ...
I0401 20:46:06.717673   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:46:06.749352   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:46:06.749360   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:46:06.810610   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:46:06.810628   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:46:06.820869   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:46:06.820879   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:46:09.331271   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:46:14.332384   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:46:14.332498   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:46:14.347641   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:46:14.347723   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:46:14.358554   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:46:14.358673   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:46:14.370012   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:46:14.370098   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:46:14.380352   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:46:14.380432   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:46:14.391486   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:46:14.391571   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:46:14.407374   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:46:14.407465   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:46:14.415141   72742 logs.go:284] 0 containers: []
W0401 20:46:14.415148   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:46:14.415226   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:46:14.426608   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:46:14.426624   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:46:14.426628   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:46:14.446063   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:46:14.446072   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:46:14.466789   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:46:14.466800   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:46:14.494177   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:46:14.494187   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:46:14.511155   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:46:14.511176   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:46:14.522614   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:46:14.522624   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:46:14.533242   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:46:14.533251   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:46:14.549798   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:46:14.549813   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:46:14.557383   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:46:14.557392   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:46:14.621330   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:46:14.621340   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:46:14.634669   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:46:14.634682   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:46:14.647741   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:46:14.647760   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:46:14.658266   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:46:14.658284   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:46:14.667463   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:46:14.667474   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:46:14.675738   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:46:14.675746   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:46:14.707469   72742 logs.go:123] Gathering logs for container status ...
I0401 20:46:14.707480   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:46:14.756818   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:46:14.756827   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:46:14.803121   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:46:14.803133   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:46:14.816380   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:46:14.816390   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:46:14.830065   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:46:14.830073   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:46:14.843361   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:46:14.843370   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:46:17.352643   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:46:22.354012   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:46:22.354180   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:46:22.367376   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:46:22.367451   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:46:22.379462   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:46:22.379535   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:46:22.391906   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:46:22.392201   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:46:22.403197   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:46:22.403279   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:46:22.412400   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:46:22.412476   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:46:22.422394   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:46:22.422490   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:46:22.429990   72742 logs.go:284] 0 containers: []
W0401 20:46:22.429998   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:46:22.430072   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:46:22.439005   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:46:22.439020   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:46:22.439038   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:46:22.454895   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:46:22.454906   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:46:22.466648   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:46:22.466663   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:46:22.476291   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:46:22.476299   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:46:22.489453   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:46:22.489464   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:46:22.503932   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:46:22.503944   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:46:22.517740   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:46:22.517750   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:46:22.530233   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:46:22.530252   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:46:22.546942   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:46:22.546951   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:46:22.584855   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:46:22.584869   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:46:22.603293   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:46:22.603305   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:46:22.618288   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:46:22.618298   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:46:22.642838   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:46:22.642851   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:46:22.663856   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:46:22.663869   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:46:22.676148   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:46:22.676160   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:46:22.696090   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:46:22.696100   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:46:22.712928   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:46:22.712944   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:46:22.724528   72742 logs.go:123] Gathering logs for container status ...
I0401 20:46:22.724538   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:46:22.762005   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:46:22.762017   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:46:22.818146   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:46:22.818157   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:46:22.891905   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:46:22.891915   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:46:25.410336   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:46:30.411773   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:46:30.411934   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:46:30.422121   72742 logs.go:284] 2 containers: [ee45f9bb3767 67d2fb78bc38]
I0401 20:46:30.422181   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:46:30.430071   72742 logs.go:284] 2 containers: [539db068dbcc bbecac00b816]
I0401 20:46:30.430142   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:46:30.439048   72742 logs.go:284] 4 containers: [92f5a3299ccc a5c2bb7564a6 c94b3ae97d6c 32928a6bdc01]
I0401 20:46:30.439093   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:46:30.454408   72742 logs.go:284] 2 containers: [9dfbbc4274fd f239a43ab556]
I0401 20:46:30.454490   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:46:30.467075   72742 logs.go:284] 2 containers: [60ce5dcf49ca 5bdab12a4437]
I0401 20:46:30.467112   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:46:30.475913   72742 logs.go:284] 2 containers: [27a9fbcdc974 60924a430bbb]
I0401 20:46:30.475939   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:46:30.482774   72742 logs.go:284] 0 containers: []
W0401 20:46:30.482781   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:46:30.482878   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:46:30.490497   72742 logs.go:284] 2 containers: [fccaac2e4c0c 421c7c96a3f0]
I0401 20:46:30.490507   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:46:30.490510   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:46:30.534709   72742 logs.go:123] Gathering logs for kube-controller-manager [27a9fbcdc974] ...
I0401 20:46:30.534717   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 27a9fbcdc974"
I0401 20:46:30.549878   72742 logs.go:123] Gathering logs for storage-provisioner [fccaac2e4c0c] ...
I0401 20:46:30.549882   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 fccaac2e4c0c"
I0401 20:46:30.562949   72742 logs.go:123] Gathering logs for storage-provisioner [421c7c96a3f0] ...
I0401 20:46:30.562963   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 421c7c96a3f0"
I0401 20:46:30.579887   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:46:30.579895   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:46:30.611471   72742 logs.go:123] Gathering logs for coredns [92f5a3299ccc] ...
I0401 20:46:30.611480   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 92f5a3299ccc"
I0401 20:46:30.621190   72742 logs.go:123] Gathering logs for coredns [c94b3ae97d6c] ...
I0401 20:46:30.621199   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 c94b3ae97d6c"
I0401 20:46:30.630638   72742 logs.go:123] Gathering logs for coredns [32928a6bdc01] ...
I0401 20:46:30.630649   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 32928a6bdc01"
I0401 20:46:30.643482   72742 logs.go:123] Gathering logs for kube-proxy [60ce5dcf49ca] ...
I0401 20:46:30.643489   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60ce5dcf49ca"
I0401 20:46:30.651385   72742 logs.go:123] Gathering logs for kube-controller-manager [60924a430bbb] ...
I0401 20:46:30.651392   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 60924a430bbb"
I0401 20:46:30.665990   72742 logs.go:123] Gathering logs for container status ...
I0401 20:46:30.666000   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:46:30.701048   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:46:30.701062   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:46:30.707925   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:46:30.707932   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:46:30.769161   72742 logs.go:123] Gathering logs for etcd [539db068dbcc] ...
I0401 20:46:30.769169   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 539db068dbcc"
I0401 20:46:30.781158   72742 logs.go:123] Gathering logs for coredns [a5c2bb7564a6] ...
I0401 20:46:30.781166   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a5c2bb7564a6"
I0401 20:46:30.789658   72742 logs.go:123] Gathering logs for kube-scheduler [f239a43ab556] ...
I0401 20:46:30.789665   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 f239a43ab556"
I0401 20:46:30.800559   72742 logs.go:123] Gathering logs for kube-apiserver [ee45f9bb3767] ...
I0401 20:46:30.800567   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 ee45f9bb3767"
I0401 20:46:30.813813   72742 logs.go:123] Gathering logs for kube-apiserver [67d2fb78bc38] ...
I0401 20:46:30.813821   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 67d2fb78bc38"
I0401 20:46:30.826448   72742 logs.go:123] Gathering logs for etcd [bbecac00b816] ...
I0401 20:46:30.826455   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 bbecac00b816"
I0401 20:46:30.838326   72742 logs.go:123] Gathering logs for kube-scheduler [9dfbbc4274fd] ...
I0401 20:46:30.838330   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9dfbbc4274fd"
I0401 20:46:30.856133   72742 logs.go:123] Gathering logs for kube-proxy [5bdab12a4437] ...
I0401 20:46:30.856137   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5bdab12a4437"
I0401 20:46:33.366048   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:46:38.367182   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:46:38.367233   72742 kubeadm.go:640] restartCluster took 4m31.995035667s
W0401 20:46:38.369432   72742 out.go:239] ü§¶  Unable to restart cluster, will reset it: apiserver health: apiserver healthz never reported healthy: context deadline exceeded
I0401 20:46:38.369481   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I0401 20:46:41.822927   72742 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (3.453434875s)
I0401 20:46:41.823226   72742 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0401 20:46:41.829484   72742 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0401 20:46:41.833549   72742 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0401 20:46:41.837581   72742 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0401 20:46:41.837603   72742 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.28.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,NumCPU,Mem"
I0401 20:46:41.864581   72742 kubeadm.go:322] [init] Using Kubernetes version: v1.28.3
I0401 20:46:41.864625   72742 kubeadm.go:322] [preflight] Running pre-flight checks
I0401 20:46:41.953674   72742 kubeadm.go:322] [preflight] Pulling images required for setting up a Kubernetes cluster
I0401 20:46:41.953725   72742 kubeadm.go:322] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0401 20:46:41.953808   72742 kubeadm.go:322] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0401 20:46:42.120874   72742 kubeadm.go:322] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0401 20:46:42.126182   72742 out.go:204]     ‚ñ™ Generating certificates and keys ...
I0401 20:46:42.126248   72742 kubeadm.go:322] [certs] Using existing ca certificate authority
I0401 20:46:42.126279   72742 kubeadm.go:322] [certs] Using existing apiserver certificate and key on disk
I0401 20:46:42.126317   72742 kubeadm.go:322] [certs] Using existing apiserver-kubelet-client certificate and key on disk
I0401 20:46:42.126339   72742 kubeadm.go:322] [certs] Using existing front-proxy-ca certificate authority
I0401 20:46:42.126370   72742 kubeadm.go:322] [certs] Using existing front-proxy-client certificate and key on disk
I0401 20:46:42.126509   72742 kubeadm.go:322] [certs] Using existing etcd/ca certificate authority
I0401 20:46:42.126549   72742 kubeadm.go:322] [certs] Using existing etcd/server certificate and key on disk
I0401 20:46:42.126580   72742 kubeadm.go:322] [certs] Using existing etcd/peer certificate and key on disk
I0401 20:46:42.126613   72742 kubeadm.go:322] [certs] Using existing etcd/healthcheck-client certificate and key on disk
I0401 20:46:42.126650   72742 kubeadm.go:322] [certs] Using existing apiserver-etcd-client certificate and key on disk
I0401 20:46:42.126670   72742 kubeadm.go:322] [certs] Using the existing "sa" key
I0401 20:46:42.126701   72742 kubeadm.go:322] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0401 20:46:42.386380   72742 kubeadm.go:322] [kubeconfig] Writing "admin.conf" kubeconfig file
I0401 20:46:42.522575   72742 kubeadm.go:322] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0401 20:46:42.620551   72742 kubeadm.go:322] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0401 20:46:42.768079   72742 kubeadm.go:322] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0401 20:46:42.768351   72742 kubeadm.go:322] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0401 20:46:42.770695   72742 kubeadm.go:322] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0401 20:46:42.777964   72742 out.go:204]     ‚ñ™ Booting up control plane ...
I0401 20:46:42.778055   72742 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0401 20:46:42.778099   72742 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0401 20:46:42.778177   72742 kubeadm.go:322] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0401 20:46:42.780772   72742 kubeadm.go:322] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0401 20:46:42.781125   72742 kubeadm.go:322] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0401 20:46:42.781251   72742 kubeadm.go:322] [kubelet-start] Starting the kubelet
I0401 20:46:42.874568   72742 kubeadm.go:322] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I0401 20:46:47.376395   72742 kubeadm.go:322] [apiclient] All control plane components are healthy after 4.501698 seconds
I0401 20:46:47.376492   72742 kubeadm.go:322] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0401 20:46:47.388741   72742 kubeadm.go:322] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0401 20:46:47.899565   72742 kubeadm.go:322] [upload-certs] Skipping phase. Please see --upload-certs
I0401 20:46:47.899708   72742 kubeadm.go:322] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0401 20:46:48.406812   72742 kubeadm.go:322] [bootstrap-token] Using token: lff18i.6vuqevmz6yyx7eet
I0401 20:46:48.413061   72742 out.go:204]     ‚ñ™ Configuring RBAC rules ...
I0401 20:46:48.413175   72742 kubeadm.go:322] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0401 20:46:48.419862   72742 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0401 20:46:48.422997   72742 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0401 20:46:48.424193   72742 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0401 20:46:48.426194   72742 kubeadm.go:322] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0401 20:46:48.428989   72742 kubeadm.go:322] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0401 20:46:48.433783   72742 kubeadm.go:322] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0401 20:46:48.624767   72742 kubeadm.go:322] [addons] Applied essential addon: CoreDNS
I0401 20:46:48.822761   72742 kubeadm.go:322] [addons] Applied essential addon: kube-proxy
I0401 20:46:48.823402   72742 kubeadm.go:322] 
I0401 20:46:48.823478   72742 kubeadm.go:322] Your Kubernetes control-plane has initialized successfully!
I0401 20:46:48.823486   72742 kubeadm.go:322] 
I0401 20:46:48.823560   72742 kubeadm.go:322] To start using your cluster, you need to run the following as a regular user:
I0401 20:46:48.823567   72742 kubeadm.go:322] 
I0401 20:46:48.823579   72742 kubeadm.go:322]   mkdir -p $HOME/.kube
I0401 20:46:48.823609   72742 kubeadm.go:322]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0401 20:46:48.823658   72742 kubeadm.go:322]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0401 20:46:48.823670   72742 kubeadm.go:322] 
I0401 20:46:48.823737   72742 kubeadm.go:322] Alternatively, if you are the root user, you can run:
I0401 20:46:48.823754   72742 kubeadm.go:322] 
I0401 20:46:48.823792   72742 kubeadm.go:322]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0401 20:46:48.823795   72742 kubeadm.go:322] 
I0401 20:46:48.823821   72742 kubeadm.go:322] You should now deploy a pod network to the cluster.
I0401 20:46:48.823870   72742 kubeadm.go:322] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0401 20:46:48.823920   72742 kubeadm.go:322]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0401 20:46:48.823922   72742 kubeadm.go:322] 
I0401 20:46:48.823981   72742 kubeadm.go:322] You can now join any number of control-plane nodes by copying certificate authorities
I0401 20:46:48.824036   72742 kubeadm.go:322] and service account keys on each node and then running the following as root:
I0401 20:46:48.824040   72742 kubeadm.go:322] 
I0401 20:46:48.824086   72742 kubeadm.go:322]   kubeadm join control-plane.minikube.internal:8443 --token lff18i.6vuqevmz6yyx7eet \
I0401 20:46:48.824164   72742 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:1d5536f8aa0423be1287ee4d8b035451e232c84046a6043d6178944c1e9a35bc \
I0401 20:46:48.824173   72742 kubeadm.go:322] 	--control-plane 
I0401 20:46:48.824178   72742 kubeadm.go:322] 
I0401 20:46:48.824236   72742 kubeadm.go:322] Then you can join any number of worker nodes by running the following on each as root:
I0401 20:46:48.824239   72742 kubeadm.go:322] 
I0401 20:46:48.824288   72742 kubeadm.go:322] kubeadm join control-plane.minikube.internal:8443 --token lff18i.6vuqevmz6yyx7eet \
I0401 20:46:48.824380   72742 kubeadm.go:322] 	--discovery-token-ca-cert-hash sha256:1d5536f8aa0423be1287ee4d8b035451e232c84046a6043d6178944c1e9a35bc 
I0401 20:46:48.824446   72742 kubeadm.go:322] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0401 20:46:48.824458   72742 cni.go:84] Creating CNI manager for ""
I0401 20:46:48.824466   72742 cni.go:158] "qemu2" driver + "docker" container runtime found on kubernetes v1.24+, recommending bridge
I0401 20:46:48.828048   72742 out.go:177] üîó  Configuring bridge CNI (Container Networking Interface) ...
I0401 20:46:48.835102   72742 ssh_runner.go:195] Run: sudo mkdir -p /etc/cni/net.d
I0401 20:46:48.839244   72742 ssh_runner.go:362] scp memory --> /etc/cni/net.d/1-k8s.conflist (457 bytes)
I0401 20:46:48.845342   72742 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0401 20:46:48.845413   72742 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.28.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0401 20:46:48.845468   72742 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.28.3/kubectl label nodes minikube.k8s.io/version=v1.32.0 minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2025_04_01T20_46_48_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0401 20:46:48.852688   72742 ops.go:34] apiserver oom_adj: -16
I0401 20:46:48.908412   72742 kubeadm.go:1081] duration metric: took 63.061ms to wait for elevateKubeSystemPrivileges.
I0401 20:46:48.918472   72742 host.go:66] Checking if "minikube" exists ...
I0401 20:46:48.919873   72742 main.go:141] libmachine: Using SSH client type: external
I0401 20:46:48.919896   72742 main.go:141] libmachine: Using SSH private key: /Users/T971012/.minikube/machines/minikube/id_rsa (-rw-------)
I0401 20:46:48.919910   72742 main.go:141] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/T971012/.minikube/machines/minikube/id_rsa -p 50440] /usr/bin/ssh <nil>}
I0401 20:46:48.919924   72742 main.go:141] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/T971012/.minikube/machines/minikube/id_rsa -p 50440 -f -NTL 65034:localhost:8443
I0401 20:46:48.977083   72742 kubeadm.go:406] StartCluster complete in 4m42.686488042s
I0401 20:46:48.977123   72742 settings.go:142] acquiring lock: {Name:mk5d843978d9860310b779df1acd02925564cc68 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0401 20:46:48.977288   72742 settings.go:150] Updating kubeconfig:  /Users/T971012/.kube/config
I0401 20:46:48.980083   72742 lock.go:35] WriteFile acquiring /Users/T971012/.kube/config: {Name:mk23b63c95b0136afdd6939e96ddddc5ca18c0aa Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0401 20:46:48.980876   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0401 20:46:48.981082   72742 addons.go:499] enable addons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false inspektor-gadget:false istio:false istio-provisioner:false kong:false kubeflow:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-device-plugin:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false storage-provisioner-rancher:false volumesnapshots:false]
I0401 20:46:48.981178   72742 addons.go:69] Setting default-storageclass=true in profile "minikube"
I0401 20:46:48.981176   72742 addons.go:69] Setting storage-provisioner=true in profile "minikube"
I0401 20:46:48.981189   72742 addons.go:231] Setting addon storage-provisioner=true in "minikube"
W0401 20:46:48.981191   72742 addons.go:240] addon storage-provisioner should already be in state true
I0401 20:46:48.981219   72742 config.go:182] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.28.3
I0401 20:46:48.981354   72742 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0401 20:46:48.981774   72742 host.go:66] Checking if "minikube" exists ...
I0401 20:46:48.982791   72742 addons.go:231] Setting addon default-storageclass=true in "minikube"
W0401 20:46:48.982793   72742 addons.go:240] addon default-storageclass should already be in state true
I0401 20:46:48.982798   72742 host.go:66] Checking if "minikube" exists ...
I0401 20:46:48.985982   72742 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0401 20:46:48.984048   72742 addons.go:423] installing /etc/kubernetes/addons/storageclass.yaml
I0401 20:46:48.985999   72742 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0401 20:46:48.989028   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
I0401 20:46:48.989102   72742 addons.go:423] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0401 20:46:48.989108   72742 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0401 20:46:48.989111   72742 sshutil.go:53] new ssh client: &{IP:localhost Port:50440 SSHKeyPath:/Users/T971012/.minikube/machines/minikube/id_rsa Username:docker}
W0401 20:46:48.990351   72742 sshutil.go:64] dial failure (will retry): ssh: handshake failed: write tcp 127.0.0.1:51675->127.0.0.1:50440: write: broken pipe
I0401 20:46:48.990376   72742 retry.go:31] will retry after 143.56259ms: ssh: handshake failed: write tcp 127.0.0.1:51675->127.0.0.1:50440: write: broken pipe
I0401 20:46:49.028384   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed -e '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           10.0.2.2 host.minikube.internal\n           fallthrough\n        }' -e '/^        errors *$/i \        log' | sudo /var/lib/minikube/binaries/v1.28.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0401 20:46:49.035179   72742 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0401 20:46:49.205659   72742 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.28.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0401 20:46:49.431702   72742 start.go:926] {"host.minikube.internal": 10.0.2.2} host record injected into CoreDNS's ConfigMap
W0401 20:47:18.984340   72742 kapi.go:245] failed rescaling "coredns" deployment in "kube-system" namespace and "minikube" context to 1 replicas: non-retryable failure while getting "coredns" deployment scale: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
E0401 20:47:18.984357   72742 start.go:219] Unable to scale down deployment "coredns" in namespace "kube-system" to 1 replica: non-retryable failure while getting "coredns" deployment scale: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
I0401 20:47:18.984427   72742 start.go:223] Will wait 6m0s for node &{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.28.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0401 20:47:18.988766   72742 out.go:177] üîé  Verifying Kubernetes components...
I0401 20:47:18.996999   72742 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0401 20:47:19.004573   72742 api_server.go:52] waiting for apiserver process to appear ...
I0401 20:47:19.004632   72742 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0401 20:47:19.010309   72742 api_server.go:72] duration metric: took 25.860917ms to wait for apiserver process to appear ...
I0401 20:47:19.010316   72742 api_server.go:88] waiting for apiserver healthz status ...
I0401 20:47:19.010322   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
W0401 20:47:19.516138   72742 out.go:239] ‚ùó  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/storageclasses": dial tcp 10.0.2.15:8443: i/o timeout]
I0401 20:47:19.519378   72742 out.go:177] üåü  Enabled addons: storage-provisioner
I0401 20:47:19.526325   72742 addons.go:502] enable addons completed in 30.545275583s: enabled=[storage-provisioner]
I0401 20:47:24.010997   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:24.011017   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:29.012350   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:29.512669   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:34.513470   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:34.513494   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:39.513762   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:39.513786   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:44.514136   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:44.514177   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:49.514611   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:49.514625   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:54.515048   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:54.515065   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:47:59.515617   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:47:59.515641   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:04.516237   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:04.516271   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:09.516961   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:09.516999   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:14.517641   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:14.517662   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:19.518597   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:19.518724   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:19.533129   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:19.534119   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:19.543751   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:19.543798   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:19.552379   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:19.552537   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:19.569855   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:19.569925   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:19.578328   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:19.578431   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:19.586553   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:19.586644   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:19.601108   72742 logs.go:284] 0 containers: []
W0401 20:48:19.601116   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:19.601256   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:19.609380   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:19.609392   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:19.609396   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:19.617288   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:19.617295   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:19.625560   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:19.625567   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:19.638142   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:19.638149   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:19.650846   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:19.650853   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:19.663551   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:19.663557   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:19.675384   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:19.675399   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:19.692637   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:19.692644   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:48:19.703222   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:19.703229   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:19.733327   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:19.733338   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:19.770385   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:19.770397   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:19.785065   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:19.785076   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:19.841803   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:19.841812   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:22.439213   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:27.440039   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:27.440156   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:27.457406   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:27.457504   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:27.465750   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:27.465820   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:27.474420   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:27.474479   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:27.483461   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:27.483521   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:27.491950   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:27.492038   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:27.500451   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:27.500508   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:27.509866   72742 logs.go:284] 0 containers: []
W0401 20:48:27.513410   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:27.513460   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:27.522316   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:27.522331   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:27.522338   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:27.534737   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:27.534745   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:27.543707   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:27.543713   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:48:27.553641   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:27.553646   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:27.587618   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:27.587624   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:27.630540   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:27.630546   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:27.637760   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:27.637762   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:27.651511   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:27.651519   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:27.665627   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:27.665633   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:27.678981   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:27.678987   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:27.744483   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:27.744490   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:27.761925   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:27.761933   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:27.800566   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:27.800573   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:30.312474   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:35.313793   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:35.313941   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:35.323766   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:35.323842   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:35.332022   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:35.332070   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:35.340402   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:35.340470   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:35.349910   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:35.349946   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:35.358535   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:35.358584   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:35.368578   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:35.368647   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:35.377086   72742 logs.go:284] 0 containers: []
W0401 20:48:35.377093   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:35.377146   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:35.389466   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:35.389487   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:35.389493   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:35.398429   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:35.398436   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:35.410974   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:35.410986   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:35.422419   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:35.422428   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:35.449537   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:35.449545   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:35.456877   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:35.456886   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:35.470406   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:35.470416   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:35.488112   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:35.488120   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:35.498753   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:35.498764   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:35.532170   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:35.532181   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:35.564896   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:35.564905   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:48:35.578096   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:35.578105   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:35.622080   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:35.622095   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:38.191553   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:43.192281   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:43.192444   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:43.200814   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:43.200844   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:43.208253   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:43.208377   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:43.216786   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:43.216861   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:43.225555   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:43.225593   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:43.233155   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:43.233195   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:43.240565   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:43.240599   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:43.248576   72742 logs.go:284] 0 containers: []
W0401 20:48:43.248588   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:43.248658   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:43.255772   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:43.255786   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:43.255790   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:43.315537   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:43.315544   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:43.328205   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:43.328213   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:43.336806   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:43.336811   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:43.350609   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:43.350616   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:43.379043   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:43.379050   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:43.386136   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:43.386139   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:43.394710   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:43.394713   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:48:43.407457   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:43.407460   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:43.437986   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:43.437990   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:43.479708   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:43.479716   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:43.493029   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:43.493035   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:43.509769   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:43.509784   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:46.026118   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:51.027396   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:51.027501   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:51.038666   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:51.038724   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:51.052651   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:51.052757   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:51.061690   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:51.061757   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:51.074246   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:51.074297   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:51.087395   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:51.087460   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:51.095635   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:51.095743   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:51.104003   72742 logs.go:284] 0 containers: []
W0401 20:48:51.104010   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:51.104065   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:51.112121   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:51.112147   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:51.112152   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:51.121333   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:51.121339   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:48:51.130616   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:51.130621   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:51.196683   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:51.196691   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:51.205770   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:51.205774   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:51.243461   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:51.243481   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:51.263571   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:51.263575   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:51.276090   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:51.276094   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:51.287261   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:51.287265   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:51.324277   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:51.324281   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:51.330763   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:51.330767   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:51.342225   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:51.342229   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:51.361385   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:51.361390   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:53.893325   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:48:58.896434   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:48:58.896598   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:48:58.904464   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:48:58.904514   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:48:58.914847   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:48:58.914928   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:48:58.922151   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:48:58.922215   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:48:58.929268   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:48:58.929325   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:48:58.935570   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:48:58.935624   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:48:58.942898   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:48:58.942986   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:48:58.949982   72742 logs.go:284] 0 containers: []
W0401 20:48:58.949985   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:48:58.950009   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:48:58.964946   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:48:58.964953   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:48:58.964956   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:48:58.976271   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:48:58.976275   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:48:58.987823   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:48:58.987829   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:48:59.002867   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:48:59.002870   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:48:59.031563   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:48:59.031567   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:48:59.044624   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:48:59.044630   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:48:59.052841   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:48:59.052844   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:48:59.059097   72742 logs.go:123] Gathering logs for container status ...
I0401 20:48:59.059100   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:48:59.089262   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:48:59.089266   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:48:59.128288   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:48:59.128298   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:48:59.190381   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:48:59.190389   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:48:59.206596   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:48:59.206601   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:48:59.216795   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:48:59.216800   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:01.726476   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:06.727751   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:06.727896   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:06.741075   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:06.741119   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:06.749273   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:06.749313   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:06.756380   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:06.756405   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:06.763389   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:06.763465   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:06.770391   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:06.770437   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:06.777628   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:06.777680   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:06.795011   72742 logs.go:284] 0 containers: []
W0401 20:49:06.795022   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:06.795075   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:06.803826   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:06.803837   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:06.803844   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:06.811788   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:06.811793   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:06.817817   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:06.817821   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:06.874432   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:06.874443   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:06.885220   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:06.885223   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:06.900631   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:06.900633   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:06.932356   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:06.932359   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:06.971150   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:06.971154   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:06.983138   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:06.983141   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:06.992463   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:06.992476   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:07.000750   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:07.000753   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:07.012104   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:07.012106   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:07.043955   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:07.043959   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:09.558596   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:14.560008   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:14.560155   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:14.570151   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:14.570217   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:14.577982   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:14.578019   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:14.587450   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:14.587481   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:14.596846   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:14.596925   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:14.607355   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:14.607484   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:14.616849   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:14.616948   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:14.626055   72742 logs.go:284] 0 containers: []
W0401 20:49:14.626063   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:14.626135   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:14.635374   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:14.635390   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:14.635396   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:14.642388   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:14.642396   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:14.656844   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:14.656852   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:14.698673   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:14.698683   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:14.714514   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:14.714522   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:14.732963   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:14.732971   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:14.741702   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:14.741707   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:14.757280   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:14.757292   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:14.765203   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:14.765209   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:14.793413   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:14.793423   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:14.822174   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:14.822180   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:14.895356   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:14.895365   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:14.905892   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:14.905895   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:17.416685   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:22.418145   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:22.418231   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:22.426064   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:22.426127   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:22.434142   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:22.434179   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:22.442144   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:22.442180   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:22.451329   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:22.451373   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:22.461039   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:22.461101   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:22.469610   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:22.469680   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:22.477808   72742 logs.go:284] 0 containers: []
W0401 20:49:22.477814   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:22.477860   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:22.486750   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:22.486767   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:22.486774   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:22.549371   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:22.549378   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:22.560572   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:22.560581   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:22.568772   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:22.568778   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:22.585925   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:22.585931   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:22.600293   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:22.600297   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:22.633398   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:22.633403   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:22.672838   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:22.672845   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:22.685044   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:22.685048   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:22.718918   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:22.718926   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:22.725922   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:22.725926   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:22.742289   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:22.742295   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:22.755946   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:22.755952   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:25.278730   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:30.280106   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:30.280241   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:30.295043   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:30.295115   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:30.309006   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:30.309035   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:30.317592   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:30.317680   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:30.325901   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:30.325955   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:30.335673   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:30.335707   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:30.343806   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:30.343837   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:30.352700   72742 logs.go:284] 0 containers: []
W0401 20:49:30.352710   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:30.352778   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:30.364584   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:30.364592   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:30.364596   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:30.377026   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:30.377034   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:30.393993   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:30.394000   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:30.430332   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:30.430339   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:30.490315   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:30.490330   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:30.509885   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:30.509891   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:30.519863   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:30.519867   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:30.550896   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:30.550902   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:30.589398   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:30.589402   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:30.599195   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:30.599199   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:30.606149   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:30.606153   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:30.620073   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:30.620079   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:30.629560   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:30.629564   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:33.138217   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:38.139713   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:38.139814   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:38.148750   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:38.148831   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:38.157520   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:38.157560   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:38.165662   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:38.165715   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:38.174917   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:38.174946   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:38.184214   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:38.184266   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:38.193593   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:38.193674   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:38.206529   72742 logs.go:284] 0 containers: []
W0401 20:49:38.206539   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:38.206598   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:38.214276   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:38.214289   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:38.214293   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:38.228555   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:38.228560   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:38.235741   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:38.235745   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:38.250469   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:38.250473   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:38.261448   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:38.261452   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:38.275205   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:38.275209   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:38.304683   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:38.304702   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:38.336097   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:38.336106   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:38.372398   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:38.372406   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:38.435606   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:38.435614   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:38.452378   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:38.452395   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:38.461482   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:38.461489   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:38.475984   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:38.475988   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:40.987810   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:45.989124   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:45.989286   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:45.999722   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:45.999782   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:46.007094   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:46.007160   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:46.015970   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:46.016043   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:46.028733   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:46.028814   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:46.036539   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:46.036573   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:46.043784   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:46.043860   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:46.051043   72742 logs.go:284] 0 containers: []
W0401 20:49:46.051058   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:46.051081   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:46.058676   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:46.058689   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:46.058693   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:46.072971   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:46.072976   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:46.136380   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:46.136388   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:46.146181   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:46.146189   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:46.164375   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:46.164382   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:46.209047   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:46.209062   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:46.222644   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:46.222649   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:46.240398   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:46.240402   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:46.273135   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:46.273144   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:46.280373   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:46.280376   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:46.298605   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:46.298610   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:46.307659   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:46.307664   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:46.317602   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:46.317606   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:48.849301   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:49:53.850641   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:49:53.850742   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:49:53.863571   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:49:53.863624   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:49:53.872638   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:49:53.872677   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:49:53.882298   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:49:53.882383   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:49:53.890395   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:49:53.890450   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:49:53.898285   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:49:53.898353   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:49:53.907189   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:49:53.907224   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:49:53.920576   72742 logs.go:284] 0 containers: []
W0401 20:49:53.920583   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:49:53.920639   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:49:53.928958   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:49:53.928978   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:49:53.928982   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:49:53.938911   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:49:53.938918   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:49:53.973061   72742 logs.go:123] Gathering logs for container status ...
I0401 20:49:53.973066   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:49:54.008381   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:49:54.008390   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:49:54.073667   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:49:54.073675   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:49:54.093243   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:49:54.093250   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:49:54.102465   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:49:54.102472   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:49:54.111473   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:49:54.111478   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:49:54.125436   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:49:54.125442   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:49:54.134801   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:49:54.134806   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:49:54.148519   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:49:54.148523   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:49:54.164188   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:49:54.164195   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:49:54.200315   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:49:54.200320   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:49:56.708906   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:01.710295   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:01.710433   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:01.718405   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:01.718470   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:01.725791   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:01.725829   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:01.733255   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:01.733273   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:01.741595   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:01.741614   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:01.749415   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:01.749485   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:01.756741   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:01.756769   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:01.763653   72742 logs.go:284] 0 containers: []
W0401 20:50:01.763660   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:01.763713   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:01.771429   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:01.771440   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:01.771443   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:01.782273   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:01.782276   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:01.814519   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:01.814525   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:01.820907   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:01.820914   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:01.829678   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:01.829681   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:01.841810   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:01.841814   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:01.907284   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:01.907289   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:01.920670   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:01.920690   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:01.929088   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:01.929091   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:01.940932   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:01.940935   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:01.953099   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:01.953103   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:01.967786   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:01.967789   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:02.010005   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:02.010012   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:04.542051   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:09.542604   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:09.542696   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:09.551870   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:09.551899   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:09.559627   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:09.559652   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:09.568271   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:09.568361   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:09.576608   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:09.576666   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:09.584662   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:09.584700   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:09.594110   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:09.594139   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:09.603248   72742 logs.go:284] 0 containers: []
W0401 20:50:09.603257   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:09.603312   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:09.610940   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:09.610951   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:09.610956   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:09.617650   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:09.617655   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:09.627745   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:09.627752   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:09.659592   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:09.659601   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:09.704009   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:09.704019   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:09.768208   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:09.768217   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:09.778920   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:09.778925   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:09.797210   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:09.797215   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:09.806810   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:09.806815   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:09.839999   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:09.840006   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:09.854941   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:09.854945   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:09.869958   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:09.869964   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:09.883214   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:09.883218   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:12.396478   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:17.397820   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:17.397957   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:17.406359   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:17.406397   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:17.414534   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:17.414596   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:17.425321   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:17.425366   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:17.434349   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:17.434384   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:17.449434   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:17.449577   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:17.457180   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:17.457219   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:17.464244   72742 logs.go:284] 0 containers: []
W0401 20:50:17.464253   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:17.464302   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:17.477632   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:17.477658   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:17.477667   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:17.506249   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:17.506256   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:17.518659   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:17.518664   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:17.529020   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:17.529024   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:17.542610   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:17.542614   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:17.560379   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:17.560383   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:17.575238   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:17.575240   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:17.616608   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:17.616613   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:17.678656   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:17.678664   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:17.692266   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:17.692271   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:17.714630   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:17.714636   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:17.724332   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:17.724337   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:17.732519   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:17.732524   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:20.266188   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:25.267463   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:25.267576   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:25.277583   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:25.277621   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:25.285917   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:25.285977   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:25.301186   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:25.301241   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:25.309283   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:25.309379   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:25.319184   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:25.319221   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:25.326953   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:25.327007   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:25.341859   72742 logs.go:284] 0 containers: []
W0401 20:50:25.341878   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:25.341940   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:25.349483   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:25.349494   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:25.349499   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:25.361934   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:25.361937   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:25.397859   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:25.397865   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:25.404780   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:25.404792   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:25.417907   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:25.417911   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:25.427663   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:25.427670   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:25.440041   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:25.440049   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:25.449382   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:25.449387   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:25.480679   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:25.480696   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:25.545190   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:25.545198   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:25.559374   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:25.559379   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:25.582157   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:25.582161   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:25.590724   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:25.590730   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:28.124548   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:33.125955   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:33.126093   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:33.136551   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:33.136590   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:33.145220   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:33.145308   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:33.157542   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:33.157620   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:33.165636   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:33.165718   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:33.174973   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:33.175030   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:33.183071   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:33.183105   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:33.190655   72742 logs.go:284] 0 containers: []
W0401 20:50:33.190660   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:33.190692   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:33.198351   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:33.198364   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:33.198369   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:33.206454   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:33.206460   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:33.276982   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:33.276989   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:33.293181   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:33.293188   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:33.329778   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:33.329783   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:33.345164   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:33.345171   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:33.353613   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:33.353616   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:33.365828   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:33.365835   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:33.378848   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:33.378852   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:33.387998   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:33.388001   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:33.404997   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:33.405000   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:33.415087   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:33.415092   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:33.447641   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:33.447649   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:35.983088   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:40.984438   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:40.984628   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:40.992948   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:40.992999   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:41.000294   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:41.000318   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:41.007142   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:41.007166   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:41.013763   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:41.013786   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:41.020359   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:41.020385   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:41.027311   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:41.027336   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:41.034740   72742 logs.go:284] 0 containers: []
W0401 20:50:41.034743   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:41.034758   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:41.046929   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:41.046940   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:41.046947   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:41.110231   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:41.110248   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:41.123328   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:41.123332   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:41.139309   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:41.139313   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:41.172586   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:41.172595   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:41.213730   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:41.213736   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:41.226342   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:41.226346   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:41.235439   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:41.235443   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:41.246669   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:41.246674   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:41.253241   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:41.253245   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:41.265262   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:41.265265   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:41.294631   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:41.294636   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:41.310859   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:41.310862   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:43.821225   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:48.822503   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:48.822613   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:48.834642   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:48.834737   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:48.845724   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:48.845781   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:48.857811   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:48.857845   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:48.864997   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:48.865057   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:48.871684   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:48.871721   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:48.885495   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:48.885513   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:48.891903   72742 logs.go:284] 0 containers: []
W0401 20:50:48.891910   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:48.891980   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:48.899209   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:48.899216   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:48.899219   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:48.939389   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:48.939397   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:48.963488   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:48.963493   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:48.978249   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:48.978262   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:48.993643   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:48.993647   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:49.002337   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:49.002340   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:49.014358   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:49.014361   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:49.023350   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:49.023352   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:49.055399   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:49.055404   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:49.088134   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:49.088142   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:49.094287   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:49.094290   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:49.154484   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:49.154487   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:49.163019   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:49.163033   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:51.675629   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:50:56.676980   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:50:56.677138   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:50:56.687595   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:50:56.687694   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:50:56.700650   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:50:56.700690   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:50:56.715209   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:50:56.715282   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:50:56.723870   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:50:56.723928   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:50:56.733101   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:50:56.733208   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:50:56.743624   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:50:56.743680   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:50:56.752892   72742 logs.go:284] 0 containers: []
W0401 20:50:56.752900   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:50:56.752935   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:50:56.760821   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:50:56.760835   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:50:56.760840   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:50:56.768440   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:50:56.768446   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:50:56.830718   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:50:56.830727   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:50:56.851097   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:50:56.851104   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:50:56.884299   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:50:56.884307   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:50:56.928311   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:50:56.928317   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:50:56.945279   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:50:56.945287   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:50:56.957464   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:50:56.957476   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:50:56.970330   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:50:56.970343   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:50:56.986049   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:50:56.986056   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:50:57.001245   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:50:57.001250   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:50:57.018996   72742 logs.go:123] Gathering logs for container status ...
I0401 20:50:57.019004   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:50:57.054199   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:50:57.054209   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:50:59.564760   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:51:04.565804   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:51:04.565938   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:51:04.575769   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:51:04.575831   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:51:04.584740   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:51:04.584796   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:51:04.592639   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:51:04.592746   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:51:04.600634   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:51:04.600669   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:51:04.609364   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:51:04.609394   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:51:04.623603   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:51:04.623642   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:51:04.631729   72742 logs.go:284] 0 containers: []
W0401 20:51:04.631731   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:51:04.631757   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:51:04.640676   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:51:04.640687   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:51:04.640690   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:51:04.653051   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:51:04.653057   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:51:04.665005   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:51:04.665008   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:51:04.681955   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:51:04.681959   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:51:04.690796   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:51:04.690799   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:51:04.732961   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:51:04.732971   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:51:04.792616   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:51:04.792623   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:51:04.807811   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:51:04.807817   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:51:04.817599   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:51:04.817603   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:51:04.829289   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:51:04.829297   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:51:04.858812   72742 logs.go:123] Gathering logs for container status ...
I0401 20:51:04.858838   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:51:04.886259   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:51:04.886265   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:51:04.892376   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:51:04.892380   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:51:07.405097   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:51:12.406506   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:51:12.406644   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0401 20:51:12.414259   72742 logs.go:284] 1 containers: [9b74f83a692b]
I0401 20:51:12.414312   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0401 20:51:12.421531   72742 logs.go:284] 1 containers: [22b3895769c5]
I0401 20:51:12.421595   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0401 20:51:12.428142   72742 logs.go:284] 2 containers: [3dac286be366 b55fc167ae77]
I0401 20:51:12.428212   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0401 20:51:12.435062   72742 logs.go:284] 1 containers: [9bca624b043d]
I0401 20:51:12.435089   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0401 20:51:12.441989   72742 logs.go:284] 1 containers: [85d92a057546]
I0401 20:51:12.442044   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0401 20:51:12.449470   72742 logs.go:284] 1 containers: [5e499a6cda10]
I0401 20:51:12.449497   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kindnet --format={{.ID}}
I0401 20:51:12.456435   72742 logs.go:284] 0 containers: []
W0401 20:51:12.456441   72742 logs.go:286] No container was found matching "kindnet"
I0401 20:51:12.456463   72742 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0401 20:51:12.467386   72742 logs.go:284] 1 containers: [a0c980560e33]
I0401 20:51:12.467397   72742 logs.go:123] Gathering logs for Docker ...
I0401 20:51:12.467403   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -u cri-docker -n 400"
I0401 20:51:12.497965   72742 logs.go:123] Gathering logs for kube-proxy [85d92a057546] ...
I0401 20:51:12.497969   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 85d92a057546"
I0401 20:51:12.506526   72742 logs.go:123] Gathering logs for kube-apiserver [9b74f83a692b] ...
I0401 20:51:12.506528   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9b74f83a692b"
I0401 20:51:12.522603   72742 logs.go:123] Gathering logs for etcd [22b3895769c5] ...
I0401 20:51:12.522608   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 22b3895769c5"
I0401 20:51:12.532679   72742 logs.go:123] Gathering logs for coredns [b55fc167ae77] ...
I0401 20:51:12.532681   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b55fc167ae77"
I0401 20:51:12.540109   72742 logs.go:123] Gathering logs for describe nodes ...
I0401 20:51:12.540111   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.28.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0401 20:51:12.589075   72742 logs.go:123] Gathering logs for dmesg ...
I0401 20:51:12.589078   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0401 20:51:12.594964   72742 logs.go:123] Gathering logs for kube-controller-manager [5e499a6cda10] ...
I0401 20:51:12.594966   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5e499a6cda10"
I0401 20:51:12.611393   72742 logs.go:123] Gathering logs for storage-provisioner [a0c980560e33] ...
I0401 20:51:12.611398   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 a0c980560e33"
I0401 20:51:12.619904   72742 logs.go:123] Gathering logs for kubelet ...
I0401 20:51:12.619907   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0401 20:51:12.657459   72742 logs.go:123] Gathering logs for kube-scheduler [9bca624b043d] ...
I0401 20:51:12.657463   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9bca624b043d"
I0401 20:51:12.668808   72742 logs.go:123] Gathering logs for container status ...
I0401 20:51:12.668811   72742 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0401 20:51:12.693482   72742 logs.go:123] Gathering logs for coredns [3dac286be366] ...
I0401 20:51:12.693486   72742 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3dac286be366"
I0401 20:51:15.202665   72742 api_server.go:253] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0401 20:51:20.204021   72742 api_server.go:269] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0401 20:51:20.208668   72742 out.go:177] 
W0401 20:51:20.211522   72742 out.go:239] ‚ùå  Exiting due to GUEST_START: failed to start node: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: context deadline exceeded
W0401 20:51:20.211532   72742 out.go:239] 
W0401 20:51:20.212528   72742 out.go:239] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    üòø  If the above advice does not help, please let us know:                             [31m‚îÇ[0m
[31m‚îÇ[0m    üëâ  https://github.com/kubernetes/minikube/issues/new/choose                           [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0401 20:51:20.225594   72742 out.go:177] 

* 
* ==> Docker <==
* -- Journal begins at Wed 2025-04-02 00:31:46 UTC, ends at Wed 2025-04-02 00:58:59 UTC. --
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.283932741Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.283960698Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.283989030Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube cri-dockerd[22697]: time="2025-04-02T00:47:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/bc99fcdec9487385b4bc97c3877b48b3fe5d9af99a6b169a027dd37737963a2d/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:47:55 minikube cri-dockerd[22697]: time="2025-04-02T00:47:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/33cf77c6b203e35923b0d2ce7367c578d80d17595421fd90f881bad19eac4fc6/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:47:55 minikube cri-dockerd[22697]: time="2025-04-02T00:47:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ced8f15a6bfe5d1b20003e6ff462de83801739ec45f087087c4afb63f9ea2cb1/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:47:55 minikube cri-dockerd[22697]: time="2025-04-02T00:47:55Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/cece2079c7ac75966cb6cf7c02b24c84c714e39196c749487449c6ef7230cd0b/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.522987086Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.523111496Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.523143620Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.523168077Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.528483799Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.528508798Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.528515464Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.528519756Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.541943054Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.541981927Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.541991843Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.541996093Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.605325368Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.605496109Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.605546023Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:47:55 minikube dockerd[22380]: time="2025-04-02T00:47:55.605613395Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.183070767Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.183132223Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.183144514Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.183151305Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube cri-dockerd[22697]: time="2025-04-02T00:48:13Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/14bcddbe0619ff36fdef12c6dd96b4da0b0c5e2e9aaa6a13ed13b187f98f7731/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.249291308Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.249329848Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.249473260Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.249507967Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.347730797Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.347779462Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.347785712Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.347789878Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.371440461Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.372076022Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.372173644Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.372209976Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.510488103Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.510631473Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.510695137Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.510725636Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube cri-dockerd[22697]: time="2025-04-02T00:48:13Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/de40aee149b6e6795e0a0215ef96a1e8dfdf15e6f153bff19636677eb6d1cc40/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:48:13 minikube cri-dockerd[22697]: time="2025-04-02T00:48:13Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/b275683234c56370f8afd1682b234a2eca875a1abc4282c25366af44f02c1456/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.657146101Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.657228098Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.657370801Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.657379009Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.711059659Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.711209737Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.711234153Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.711265527Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube cri-dockerd[22697]: time="2025-04-02T00:48:13Z" level=info msg="Will attempt to re-write config file /var/lib/docker/containers/ca80dc4152412016c299b15d0a14f847abfb67ecdbbf48b6ea7192193409bd31/resolv.conf as [nameserver 10.0.2.3]"
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.787940700Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.787970698Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.pause\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.787976865Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Apr 02 00:48:13 minikube dockerd[22380]: time="2025-04-02T00:48:13.787981156Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Apr 02 00:48:20 minikube cri-dockerd[22697]: time="2025-04-02T00:48:20Z" level=info msg="Docker cri received runtime config &RuntimeConfig{NetworkConfig:&NetworkConfig{PodCidr:10.244.0.0/24,},}"

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID              POD
a0c980560e336       ba04bb24b9575       10 minutes ago      Running             storage-provisioner       0                   ca80dc4152412       storage-provisioner
3dac286be366f       97e04611ad434       10 minutes ago      Running             coredns                   0                   b275683234c56       coredns-5dd5756b68-ltx45
b55fc167ae779       97e04611ad434       10 minutes ago      Running             coredns                   0                   de40aee149b6e       coredns-5dd5756b68-t2qv7
85d92a0575467       a5dd5cdd6d3ef       10 minutes ago      Running             kube-proxy                0                   14bcddbe0619f       kube-proxy-npmgq
9bca624b043d3       42a4e73724daa       11 minutes ago      Running             kube-scheduler            0                   cece2079c7ac7       kube-scheduler-minikube
22b3895769c5d       9cdd6470f48c8       11 minutes ago      Running             etcd                      0                   ced8f15a6bfe5       etcd-minikube
5e499a6cda101       8276439b4f237       11 minutes ago      Running             kube-controller-manager   0                   33cf77c6b203e       kube-controller-manager-minikube
9b74f83a692b1       537e9a59ee2fd       11 minutes ago      Running             kube-apiserver            0                   bc99fcdec9487       kube-apiserver-minikube

* 
* ==> coredns [3dac286be366] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 4369d49e705690634e66dc4876ba448687add67b4e702a1c8bd9cbe26bf81de42209d08c6b52f2167c69004abbe79b233480d7bb5830c218d455f30e7efd3686
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:55525 - 25030 "HINFO IN 6365450107681052835.6383499775752240132. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.062084306s

* 
* ==> coredns [b55fc167ae77] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 4369d49e705690634e66dc4876ba448687add67b4e702a1c8bd9cbe26bf81de42209d08c6b52f2167c69004abbe79b233480d7bb5830c218d455f30e7efd3686
CoreDNS-1.10.1
linux/arm64, go1.20, 055b2c3
[INFO] 127.0.0.1:50405 - 29247 "HINFO IN 7324529867315023953.5194935128418836782. udp 57 false 512" NXDOMAIN qr,rd,ra 132 0.12974648s

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=8220a6eb95f0a4d75f7f2d7b14cef975f050512d
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2025_04_01T20_46_48_0700
                    minikube.k8s.io/version=v1.32.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Wed, 02 Apr 2025 00:47:57 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 02 Apr 2025 00:58:51 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 02 Apr 2025 00:58:31 +0000   Wed, 02 Apr 2025 00:47:56 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 02 Apr 2025 00:58:31 +0000   Wed, 02 Apr 2025 00:47:56 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 02 Apr 2025 00:58:31 +0000   Wed, 02 Apr 2025 00:47:56 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 02 Apr 2025 00:58:31 +0000   Wed, 02 Apr 2025 00:47:57 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.0.2.15
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905072Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905072Ki
  pods:               110
System Info:
  Machine ID:                 e18f9792f02f4fbab4b975387f9fa267
  System UUID:                e18f9792f02f4fbab4b975387f9fa267
  Boot ID:                    9daefabd-4fc4-4edb-a563-cb90a8df04e5
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://24.0.7
  Kubelet Version:            v1.28.3
  Kube-Proxy Version:         v1.28.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-5dd5756b68-ltx45            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     10m
  kube-system                 coredns-5dd5756b68-t2qv7            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     10m
  kube-system                 etcd-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         11m
  kube-system                 kube-apiserver-minikube             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11m
  kube-system                 kube-controller-manager-minikube    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11m
  kube-system                 kube-proxy-npmgq                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 kube-scheduler-minikube             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         11m
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%!)(MISSING)  0 (0%!)(MISSING)
  memory             240Mi (6%!)(MISSING)  340Mi (8%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 10m                kube-proxy       
  Normal  Starting                 11m                kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  11m (x8 over 11m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    11m (x8 over 11m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     11m (x7 over 11m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  11m                kubelet          Updated Node Allocatable limit across pods
  Normal  Starting                 11m                kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  11m                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  11m                kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    11m                kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     11m                kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  RegisteredNode           10m                node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Apr 2 00:32] efi: memattr: Unexpected EFI Memory Attributes table version 2
[  +0.000000] ACPI: SRAT not present
[  +0.000000] KASLR disabled due to lack of seed
[  +1.081582] EINJ: EINJ table not found.
[  +0.767632] systemd-fstab-generator[117]: Ignoring "noauto" for root device
[  +0.049222] systemd[1]: systemd-journald.service: unit configures an IP firewall, but the local system does not support BPF/cgroup firewalling.
[  +0.001440] systemd[1]: (This warning is only shown for the first unit using IP firewalling.)
[Apr 2 00:33] systemd-fstab-generator[470]: Ignoring "noauto" for root device
[  +0.096561] systemd-fstab-generator[481]: Ignoring "noauto" for root device
[  +0.963164] systemd-fstab-generator[690]: Ignoring "noauto" for root device
[  +0.231376] systemd-fstab-generator[728]: Ignoring "noauto" for root device
[  +0.064461] systemd-fstab-generator[739]: Ignoring "noauto" for root device
[  +0.084389] systemd-fstab-generator[752]: Ignoring "noauto" for root device
[  +1.327135] systemd-fstab-generator[941]: Ignoring "noauto" for root device
[  +0.080043] systemd-fstab-generator[952]: Ignoring "noauto" for root device
[  +0.077271] systemd-fstab-generator[963]: Ignoring "noauto" for root device
[  +0.073040] systemd-fstab-generator[974]: Ignoring "noauto" for root device
[  +0.086065] systemd-fstab-generator[1009]: Ignoring "noauto" for root device
[ +11.271313] systemd-fstab-generator[1245]: Ignoring "noauto" for root device
[  +0.213823] kauditd_printk_skb: 67 callbacks suppressed
[  +6.134725] kauditd_printk_skb: 2 callbacks suppressed
[ +10.611958] kauditd_printk_skb: 14 callbacks suppressed
[Apr 2 00:37] systemd-fstab-generator[13237]: Ignoring "noauto" for root device
[  +5.149568] systemd-fstab-generator[14094]: Ignoring "noauto" for root device
[Apr 2 00:43] systemd-fstab-generator[21862]: Ignoring "noauto" for root device
[  +0.187129] systemd-fstab-generator[21895]: Ignoring "noauto" for root device
[  +0.097623] systemd-fstab-generator[21906]: Ignoring "noauto" for root device
[  +0.102018] systemd-fstab-generator[21919]: Ignoring "noauto" for root device
[  +5.136625] kauditd_printk_skb: 6 callbacks suppressed
[  +6.284364] systemd-fstab-generator[22525]: Ignoring "noauto" for root device
[  +0.100965] systemd-fstab-generator[22536]: Ignoring "noauto" for root device
[  +0.102543] systemd-fstab-generator[22547]: Ignoring "noauto" for root device
[  +0.089977] systemd-fstab-generator[22558]: Ignoring "noauto" for root device
[  +0.111228] systemd-fstab-generator[22597]: Ignoring "noauto" for root device
[  +6.389553] kauditd_printk_skb: 29 callbacks suppressed
[ +15.157794] kauditd_printk_skb: 4 callbacks suppressed
[  +7.210593] systemd-fstab-generator[24984]: Ignoring "noauto" for root device
[Apr 2 00:44] kauditd_printk_skb: 2 callbacks suppressed
[Apr 2 00:47] systemd-fstab-generator[35718]: Ignoring "noauto" for root device
[  +5.659589] systemd-fstab-generator[36336]: Ignoring "noauto" for root device

* 
* ==> etcd [22b3895769c5] <==
* {"level":"warn","ts":"2025-04-02T00:47:55.628063Z","caller":"embed/config.go:673","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2025-04-02T00:47:55.628145Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://10.0.2.15:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://10.0.2.15:2380","--initial-cluster=minikube=https://10.0.2.15:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://10.0.2.15:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://10.0.2.15:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"warn","ts":"2025-04-02T00:47:55.628177Z","caller":"embed/config.go:673","msg":"Running http and grpc server on single port. This is not recommended for production."}
{"level":"info","ts":"2025-04-02T00:47:55.628181Z","caller":"embed/etcd.go:127","msg":"configuring peer listeners","listen-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2025-04-02T00:47:55.628201Z","caller":"embed/etcd.go:495","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2025-04-02T00:47:55.630012Z","caller":"embed/etcd.go:135","msg":"configuring client listeners","listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"]}
{"level":"info","ts":"2025-04-02T00:47:55.630115Z","caller":"embed/etcd.go:309","msg":"starting an etcd server","etcd-version":"3.5.9","git-sha":"bdbbde998","go-version":"go1.19.9","go-os":"linux","go-arch":"arm64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"max-wals":5,"max-snapshots":5,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://10.0.2.15:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-backend-bytes":2147483648,"max-request-bytes":1572864,"max-concurrent-streams":4294967295,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","compact-check-time-enabled":false,"compact-check-time-interval":"1m0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2025-04-02T00:47:55.658144Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"27.915667ms"}
{"level":"info","ts":"2025-04-02T00:47:55.659972Z","caller":"etcdserver/raft.go:495","msg":"starting local member","local-member-id":"f074a195de705325","cluster-id":"ef296cf39f5d9d66"}
{"level":"info","ts":"2025-04-02T00:47:55.660009Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=()"}
{"level":"info","ts":"2025-04-02T00:47:55.660037Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 0"}
{"level":"info","ts":"2025-04-02T00:47:55.660043Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft f074a195de705325 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2025-04-02T00:47:55.660047Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 1"}
{"level":"info","ts":"2025-04-02T00:47:55.660072Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"warn","ts":"2025-04-02T00:47:55.661651Z","caller":"auth/store.go:1238","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2025-04-02T00:47:55.68761Z","caller":"mvcc/kvstore.go:393","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2025-04-02T00:47:55.70341Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2025-04-02T00:47:55.714Z","caller":"etcdserver/server.go:854","msg":"starting etcd server","local-member-id":"f074a195de705325","local-server-version":"3.5.9","cluster-version":"to_be_decided"}
{"level":"info","ts":"2025-04-02T00:47:55.716246Z","caller":"embed/etcd.go:726","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2025-04-02T00:47:55.720317Z","caller":"embed/etcd.go:278","msg":"now serving peer/client/metrics","local-member-id":"f074a195de705325","initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2025-04-02T00:47:55.723391Z","caller":"embed/etcd.go:855","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2025-04-02T00:47:55.723516Z","caller":"embed/etcd.go:597","msg":"serving peer traffic","address":"10.0.2.15:2380"}
{"level":"info","ts":"2025-04-02T00:47:55.723532Z","caller":"embed/etcd.go:569","msg":"cmux::serve","address":"10.0.2.15:2380"}
{"level":"info","ts":"2025-04-02T00:47:55.723862Z","caller":"etcdserver/server.go:738","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"f074a195de705325","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2025-04-02T00:47:55.723909Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap.db","max":5,"interval":"30s"}
{"level":"info","ts":"2025-04-02T00:47:55.723947Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/snap","suffix":"snap","max":5,"interval":"30s"}
{"level":"info","ts":"2025-04-02T00:47:55.723957Z","caller":"fileutil/purge.go:44","msg":"started to purge file","dir":"/var/lib/minikube/etcd/member/wal","suffix":"wal","max":5,"interval":"30s"}
{"level":"info","ts":"2025-04-02T00:47:55.724135Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"info","ts":"2025-04-02T00:47:55.724197Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","added-peer-id":"f074a195de705325","added-peer-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2025-04-02T00:47:56.560616Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 is starting a new election at term 1"}
{"level":"info","ts":"2025-04-02T00:47:56.560656Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became pre-candidate at term 1"}
{"level":"info","ts":"2025-04-02T00:47:56.560739Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgPreVoteResp from f074a195de705325 at term 1"}
{"level":"info","ts":"2025-04-02T00:47:56.560758Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became candidate at term 2"}
{"level":"info","ts":"2025-04-02T00:47:56.560763Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgVoteResp from f074a195de705325 at term 2"}
{"level":"info","ts":"2025-04-02T00:47:56.560769Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became leader at term 2"}
{"level":"info","ts":"2025-04-02T00:47:56.560781Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: f074a195de705325 elected leader f074a195de705325 at term 2"}
{"level":"info","ts":"2025-04-02T00:47:56.561783Z","caller":"etcdserver/server.go:2571","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2025-04-02T00:47:56.562301Z","caller":"etcdserver/server.go:2062","msg":"published local member to cluster through raft","local-member-id":"f074a195de705325","local-member-attributes":"{Name:minikube ClientURLs:[https://10.0.2.15:2379]}","request-path":"/0/members/f074a195de705325/attributes","cluster-id":"ef296cf39f5d9d66","publish-timeout":"7s"}
{"level":"info","ts":"2025-04-02T00:47:56.562482Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-04-02T00:47:56.562594Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","cluster-version":"3.5"}
{"level":"info","ts":"2025-04-02T00:47:56.562707Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2025-04-02T00:47:56.562722Z","caller":"etcdserver/server.go:2595","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2025-04-02T00:47:56.562727Z","caller":"embed/serve.go:103","msg":"ready to serve client requests"}
{"level":"info","ts":"2025-04-02T00:47:56.563327Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"10.0.2.15:2379"}
{"level":"info","ts":"2025-04-02T00:47:56.563542Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2025-04-02T00:47:56.563558Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2025-04-02T00:47:56.569495Z","caller":"embed/serve.go:250","msg":"serving client traffic securely","traffic":"grpc+http","address":"127.0.0.1:2379"}
{"level":"info","ts":"2025-04-02T00:57:56.58715Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":649}
{"level":"info","ts":"2025-04-02T00:57:56.588462Z","caller":"mvcc/kvstore_compaction.go:66","msg":"finished scheduled compaction","compact-revision":649,"took":"873.717¬µs","hash":344081664}
{"level":"info","ts":"2025-04-02T00:57:56.588489Z","caller":"mvcc/hash.go:137","msg":"storing new hash","hash":344081664,"revision":649,"compact-revision":-1}

* 
* ==> kernel <==
*  00:59:00 up 26 min,  0 users,  load average: 0.15, 0.19, 0.22
Linux minikube 5.10.57 #1 SMP PREEMPT Tue Nov 7 03:57:18 UTC 2023 aarch64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [9b74f83a692b] <==
* I0402 00:47:57.320371       1 secure_serving.go:213] Serving securely on [::]:8443
I0402 00:47:57.320444       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0402 00:47:57.320617       1 controller.go:116] Starting legacy_token_tracking_controller
I0402 00:47:57.320638       1 shared_informer.go:311] Waiting for caches to sync for configmaps
I0402 00:47:57.321185       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0402 00:47:57.321306       1 gc_controller.go:78] Starting apiserver lease garbage collector
I0402 00:47:57.321355       1 system_namespaces_controller.go:67] Starting system namespaces controller
I0402 00:47:57.322429       1 controller.go:78] Starting OpenAPI AggregationController
I0402 00:47:57.322467       1 handler_discovery.go:412] Starting ResourceDiscoveryManager
I0402 00:47:57.322657       1 available_controller.go:423] Starting AvailableConditionController
I0402 00:47:57.322675       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0402 00:47:57.322696       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0402 00:47:57.322802       1 customresource_discovery_controller.go:289] Starting DiscoveryController
I0402 00:47:57.322838       1 apf_controller.go:372] Starting API Priority and Fairness config controller
I0402 00:47:57.322961       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0402 00:47:57.322979       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0402 00:47:57.323120       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0402 00:47:57.323139       1 shared_informer.go:311] Waiting for caches to sync for cluster_authentication_trust_controller
I0402 00:47:57.323186       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0402 00:47:57.323266       1 aggregator.go:164] waiting for initial CRD sync...
I0402 00:47:57.342770       1 controller.go:134] Starting OpenAPI controller
I0402 00:47:57.342821       1 controller.go:85] Starting OpenAPI V3 controller
I0402 00:47:57.342840       1 naming_controller.go:291] Starting NamingConditionController
I0402 00:47:57.342865       1 establishing_controller.go:76] Starting EstablishingController
I0402 00:47:57.342925       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0402 00:47:57.342951       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0402 00:47:57.343002       1 crd_finalizer.go:266] Starting CRDFinalizer
I0402 00:47:57.343054       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0402 00:47:57.343111       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0402 00:47:57.343772       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0402 00:47:57.343793       1 shared_informer.go:311] Waiting for caches to sync for crd-autoregister
I0402 00:47:57.426374       1 shared_informer.go:318] Caches are synced for cluster_authentication_trust_controller
I0402 00:47:57.426614       1 apf_controller.go:377] Running API Priority and Fairness config worker
I0402 00:47:57.426634       1 apf_controller.go:380] Running API Priority and Fairness periodic rebalancing process
I0402 00:47:57.426684       1 shared_informer.go:318] Caches are synced for configmaps
I0402 00:47:57.426848       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0402 00:47:57.427037       1 shared_informer.go:318] Caches are synced for node_authorizer
I0402 00:47:57.426374       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0402 00:47:57.428140       1 controller.go:624] quota admission added evaluator for: namespaces
I0402 00:47:57.438364       1 controller.go:624] quota admission added evaluator for: leases.coordination.k8s.io
I0402 00:47:57.444694       1 shared_informer.go:318] Caches are synced for crd-autoregister
I0402 00:47:57.444732       1 aggregator.go:166] initial CRD sync complete...
I0402 00:47:57.444767       1 autoregister_controller.go:141] Starting autoregister controller
I0402 00:47:57.444806       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0402 00:47:57.444811       1 cache.go:39] Caches are synced for autoregister controller
I0402 00:47:58.327795       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0402 00:47:58.329747       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0402 00:47:58.329756       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0402 00:47:58.480069       1 controller.go:624] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0402 00:47:58.492545       1 controller.go:624] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0402 00:47:58.536719       1 alloc.go:330] "allocated clusterIPs" service="default/kubernetes" clusterIPs={"IPv4":"10.96.0.1"}
W0402 00:47:58.539555       1 lease.go:263] Resetting endpoints for master service "kubernetes" to [10.0.2.15]
I0402 00:47:58.539974       1 controller.go:624] quota admission added evaluator for: endpoints
I0402 00:47:58.541557       1 controller.go:624] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0402 00:47:59.364405       1 controller.go:624] quota admission added evaluator for: serviceaccounts
I0402 00:48:00.119672       1 controller.go:624] quota admission added evaluator for: deployments.apps
I0402 00:48:00.125016       1 alloc.go:330] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs={"IPv4":"10.96.0.10"}
I0402 00:48:00.130886       1 controller.go:624] quota admission added evaluator for: daemonsets.apps
I0402 00:48:12.376127       1 controller.go:624] quota admission added evaluator for: replicasets.apps
I0402 00:48:12.817320       1 controller.go:624] quota admission added evaluator for: controllerrevisions.apps

* 
* ==> kube-controller-manager [5e499a6cda10] <==
* I0402 00:48:12.366144       1 shared_informer.go:318] Caches are synced for deployment
I0402 00:48:12.366941       1 shared_informer.go:318] Caches are synced for ephemeral
I0402 00:48:12.369119       1 shared_informer.go:318] Caches are synced for HPA
I0402 00:48:12.371238       1 shared_informer.go:318] Caches are synced for node
I0402 00:48:12.371318       1 range_allocator.go:174] "Sending events to api server"
I0402 00:48:12.371359       1 range_allocator.go:178] "Starting range CIDR allocator"
I0402 00:48:12.371439       1 shared_informer.go:311] Waiting for caches to sync for cidrallocator
I0402 00:48:12.371459       1 shared_informer.go:318] Caches are synced for cidrallocator
I0402 00:48:12.373233       1 shared_informer.go:318] Caches are synced for taint
I0402 00:48:12.373389       1 node_lifecycle_controller.go:1225] "Initializing eviction metric for zone" zone=""
I0402 00:48:12.373469       1 node_lifecycle_controller.go:877] "Missing timestamp for Node. Assuming now as a timestamp" node="minikube"
I0402 00:48:12.373528       1 node_lifecycle_controller.go:1071] "Controller detected that zone is now in new state" zone="" newState="Normal"
I0402 00:48:12.373574       1 taint_manager.go:206] "Starting NoExecuteTaintManager"
I0402 00:48:12.373605       1 taint_manager.go:211] "Sending events to api server"
I0402 00:48:12.374087       1 event.go:307] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0402 00:48:12.374761       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-serving
I0402 00:48:12.375879       1 shared_informer.go:318] Caches are synced for daemon sets
I0402 00:48:12.376953       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-legacy-unknown
I0402 00:48:12.377011       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kubelet-client
I0402 00:48:12.377032       1 shared_informer.go:318] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0402 00:48:12.378121       1 shared_informer.go:318] Caches are synced for TTL after finished
I0402 00:48:12.381203       1 shared_informer.go:318] Caches are synced for persistent volume
I0402 00:48:12.383899       1 shared_informer.go:318] Caches are synced for crt configmap
I0402 00:48:12.383973       1 shared_informer.go:318] Caches are synced for PVC protection
I0402 00:48:12.385363       1 range_allocator.go:380] "Set node PodCIDR" node="minikube" podCIDRs=["10.244.0.0/24"]
I0402 00:48:12.386689       1 event.go:307] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-5dd5756b68 to 2"
I0402 00:48:12.396509       1 shared_informer.go:318] Caches are synced for ReplicaSet
I0402 00:48:12.399315       1 shared_informer.go:318] Caches are synced for namespace
I0402 00:48:12.404810       1 shared_informer.go:318] Caches are synced for disruption
I0402 00:48:12.408033       1 shared_informer.go:318] Caches are synced for expand
I0402 00:48:12.413323       1 shared_informer.go:318] Caches are synced for PV protection
I0402 00:48:12.414406       1 shared_informer.go:318] Caches are synced for job
I0402 00:48:12.414510       1 shared_informer.go:318] Caches are synced for certificate-csrapproving
I0402 00:48:12.414734       1 shared_informer.go:318] Caches are synced for bootstrap_signer
I0402 00:48:12.415028       1 shared_informer.go:318] Caches are synced for GC
I0402 00:48:12.415928       1 shared_informer.go:318] Caches are synced for endpoint
I0402 00:48:12.417191       1 shared_informer.go:318] Caches are synced for ReplicationController
I0402 00:48:12.421785       1 shared_informer.go:318] Caches are synced for service account
I0402 00:48:12.465700       1 shared_informer.go:318] Caches are synced for endpoint_slice_mirroring
I0402 00:48:12.488440       1 shared_informer.go:318] Caches are synced for endpoint_slice
I0402 00:48:12.513839       1 shared_informer.go:318] Caches are synced for cronjob
I0402 00:48:12.514905       1 shared_informer.go:318] Caches are synced for resource quota
I0402 00:48:12.519257       1 shared_informer.go:318] Caches are synced for resource quota
I0402 00:48:12.823793       1 event.go:307] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-npmgq"
I0402 00:48:12.939988       1 shared_informer.go:318] Caches are synced for garbage collector
I0402 00:48:12.971342       1 event.go:307] "Event occurred" object="kube-system/coredns-5dd5756b68" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-5dd5756b68-t2qv7"
I0402 00:48:12.975327       1 event.go:307] "Event occurred" object="kube-system/coredns-5dd5756b68" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-5dd5756b68-ltx45"
I0402 00:48:12.982324       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="585.775332ms"
I0402 00:48:12.988445       1 shared_informer.go:318] Caches are synced for garbage collector
I0402 00:48:12.988548       1 garbagecollector.go:166] "All resource monitors have synced. Proceeding to collect garbage"
I0402 00:48:12.988735       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="6.31548ms"
I0402 00:48:12.988987       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="43.29¬µs"
I0402 00:48:12.994711       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="15.291¬µs"
I0402 00:48:13.002625       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="36.791¬µs"
I0402 00:48:14.326419       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="37.999¬µs"
I0402 00:48:14.345373       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="4.64309ms"
I0402 00:48:14.345459       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="23.541¬µs"
I0402 00:48:14.356234       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="19.832¬µs"
I0402 00:48:14.364463       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="3.258013ms"
I0402 00:48:14.364686       1 replica_set.go:676] "Finished syncing" kind="ReplicaSet" key="kube-system/coredns-5dd5756b68" duration="23.041¬µs"

* 
* ==> kube-proxy [85d92a057546] <==
* I0402 00:48:13.383424       1 server_others.go:69] "Using iptables proxy"
I0402 00:48:13.395515       1 node.go:141] Successfully retrieved node IP: 10.0.2.15
I0402 00:48:13.424321       1 server_others.go:121] "No iptables support for family" ipFamily="IPv6"
I0402 00:48:13.424354       1 server.go:634] "kube-proxy running in single-stack mode" ipFamily="IPv4"
I0402 00:48:13.425573       1 server_others.go:152] "Using iptables Proxier"
I0402 00:48:13.425712       1 proxier.go:251] "Setting route_localnet=1 to allow node-ports on localhost; to change this either disable iptables.localhostNodePorts (--iptables-localhost-nodeports) or set nodePortAddresses (--nodeport-addresses) to filter loopback addresses"
I0402 00:48:13.425867       1 server.go:846] "Version info" version="v1.28.3"
I0402 00:48:13.425887       1 server.go:848] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0402 00:48:13.426968       1 config.go:188] "Starting service config controller"
I0402 00:48:13.426976       1 shared_informer.go:311] Waiting for caches to sync for service config
I0402 00:48:13.426985       1 config.go:97] "Starting endpoint slice config controller"
I0402 00:48:13.426987       1 shared_informer.go:311] Waiting for caches to sync for endpoint slice config
I0402 00:48:13.427225       1 config.go:315] "Starting node config controller"
I0402 00:48:13.427227       1 shared_informer.go:311] Waiting for caches to sync for node config
I0402 00:48:13.528110       1 shared_informer.go:318] Caches are synced for node config
I0402 00:48:13.541571       1 shared_informer.go:318] Caches are synced for service config
I0402 00:48:13.541587       1 shared_informer.go:318] Caches are synced for endpoint slice config

* 
* ==> kube-scheduler [9bca624b043d] <==
* I0402 00:47:56.530595       1 serving.go:348] Generated self-signed cert in-memory
W0402 00:47:57.371708       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0402 00:47:57.371804       1 authentication.go:368] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0402 00:47:57.371829       1 authentication.go:369] Continuing without authentication configuration. This may treat all requests as anonymous.
W0402 00:47:57.371857       1 authentication.go:370] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0402 00:47:57.396396       1 server.go:154] "Starting Kubernetes Scheduler" version="v1.28.3"
I0402 00:47:57.396414       1 server.go:156] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0402 00:47:57.397922       1 secure_serving.go:213] Serving securely on 127.0.0.1:10259
I0402 00:47:57.398006       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0402 00:47:57.398031       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0402 00:47:57.398047       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0402 00:47:57.408337       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0402 00:47:57.408458       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0402 00:47:57.415342       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0402 00:47:57.415529       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0402 00:47:57.415716       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0402 00:47:57.415748       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0402 00:47:57.415805       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0402 00:47:57.415842       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0402 00:47:57.415894       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0402 00:47:57.415926       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0402 00:47:57.415970       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0402 00:47:57.415983       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0402 00:47:57.416036       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:57.416070       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0402 00:47:57.416174       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:57.416206       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0402 00:47:57.416276       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0402 00:47:57.416307       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0402 00:47:57.416392       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0402 00:47:57.416445       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0402 00:47:57.416492       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0402 00:47:57.416552       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0402 00:47:57.416657       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0402 00:47:57.416681       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0402 00:47:57.416734       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0402 00:47:57.416753       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0402 00:47:57.416819       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:57.416857       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0402 00:47:57.416898       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:57.416916       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0402 00:47:58.213909       1 reflector.go:535] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0402 00:47:58.213989       1 reflector.go:147] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0402 00:47:58.232893       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:58.232929       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0402 00:47:58.342828       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0402 00:47:58.342909       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0402 00:47:58.392070       1 reflector.go:535] vendor/k8s.io/client-go/informers/factory.go:150: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0402 00:47:58.392493       1 reflector.go:147] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
I0402 00:48:01.099026       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Journal begins at Wed 2025-04-02 00:31:46 UTC, ends at Wed 2025-04-02 00:59:00 UTC. --
Apr 02 00:48:12 minikube kubelet[36342]: I0402 00:48:12.943016   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/2e15b8d7-7ebc-43b3-bb1f-b35b0139119b-xtables-lock\") pod \"kube-proxy-npmgq\" (UID: \"2e15b8d7-7ebc-43b3-bb1f-b35b0139119b\") " pod="kube-system/kube-proxy-npmgq"
Apr 02 00:48:12 minikube kubelet[36342]: I0402 00:48:12.943108   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/2e15b8d7-7ebc-43b3-bb1f-b35b0139119b-lib-modules\") pod \"kube-proxy-npmgq\" (UID: \"2e15b8d7-7ebc-43b3-bb1f-b35b0139119b\") " pod="kube-system/kube-proxy-npmgq"
Apr 02 00:48:12 minikube kubelet[36342]: I0402 00:48:12.977944   36342 topology_manager.go:215] "Topology Admit Handler" podUID="2d0f1363-875d-413a-a6bb-a1d3311f4afe" podNamespace="kube-system" podName="coredns-5dd5756b68-t2qv7"
Apr 02 00:48:12 minikube kubelet[36342]: I0402 00:48:12.978966   36342 topology_manager.go:215] "Topology Admit Handler" podUID="e5966131-b19e-4138-9185-19e16621e6c4" podNamespace="kube-system" podName="coredns-5dd5756b68-ltx45"
Apr 02 00:48:13 minikube kubelet[36342]: I0402 00:48:13.043997   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ch4pg\" (UniqueName: \"kubernetes.io/projected/e5966131-b19e-4138-9185-19e16621e6c4-kube-api-access-ch4pg\") pod \"coredns-5dd5756b68-ltx45\" (UID: \"e5966131-b19e-4138-9185-19e16621e6c4\") " pod="kube-system/coredns-5dd5756b68-ltx45"
Apr 02 00:48:13 minikube kubelet[36342]: I0402 00:48:13.044145   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lxwrp\" (UniqueName: \"kubernetes.io/projected/2d0f1363-875d-413a-a6bb-a1d3311f4afe-kube-api-access-lxwrp\") pod \"coredns-5dd5756b68-t2qv7\" (UID: \"2d0f1363-875d-413a-a6bb-a1d3311f4afe\") " pod="kube-system/coredns-5dd5756b68-t2qv7"
Apr 02 00:48:13 minikube kubelet[36342]: I0402 00:48:13.044212   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/e5966131-b19e-4138-9185-19e16621e6c4-config-volume\") pod \"coredns-5dd5756b68-ltx45\" (UID: \"e5966131-b19e-4138-9185-19e16621e6c4\") " pod="kube-system/coredns-5dd5756b68-ltx45"
Apr 02 00:48:13 minikube kubelet[36342]: I0402 00:48:13.044247   36342 reconciler_common.go:258] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/2d0f1363-875d-413a-a6bb-a1d3311f4afe-config-volume\") pod \"coredns-5dd5756b68-t2qv7\" (UID: \"2d0f1363-875d-413a-a6bb-a1d3311f4afe\") " pod="kube-system/coredns-5dd5756b68-t2qv7"
Apr 02 00:48:14 minikube kubelet[36342]: I0402 00:48:14.333872   36342 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/kube-proxy-npmgq" podStartSLOduration=2.3338453120000002 podCreationTimestamp="2025-04-02 00:48:12 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-04-02 00:48:14.333742607 +0000 UTC m=+14.254302947" watchObservedRunningTime="2025-04-02 00:48:14.333845312 +0000 UTC m=+14.254405651"
Apr 02 00:48:14 minikube kubelet[36342]: I0402 00:48:14.333906   36342 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-5dd5756b68-t2qv7" podStartSLOduration=2.333898726 podCreationTimestamp="2025-04-02 00:48:12 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-04-02 00:48:14.324643087 +0000 UTC m=+14.245203427" watchObservedRunningTime="2025-04-02 00:48:14.333898726 +0000 UTC m=+14.254459024"
Apr 02 00:48:14 minikube kubelet[36342]: I0402 00:48:14.355447   36342 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/coredns-5dd5756b68-ltx45" podStartSLOduration=2.355424277 podCreationTimestamp="2025-04-02 00:48:12 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-04-02 00:48:14.355394903 +0000 UTC m=+14.275955201" watchObservedRunningTime="2025-04-02 00:48:14.355424277 +0000 UTC m=+14.275984617"
Apr 02 00:48:14 minikube kubelet[36342]: I0402 00:48:14.355563   36342 pod_startup_latency_tracker.go:102] "Observed pod startup duration" pod="kube-system/storage-provisioner" podStartSLOduration=13.355539898 podCreationTimestamp="2025-04-02 00:48:01 +0000 UTC" firstStartedPulling="0001-01-01 00:00:00 +0000 UTC" lastFinishedPulling="0001-01-01 00:00:00 +0000 UTC" observedRunningTime="2025-04-02 00:48:14.349194242 +0000 UTC m=+14.269754581" watchObservedRunningTime="2025-04-02 00:48:14.355539898 +0000 UTC m=+14.276100196"
Apr 02 00:48:20 minikube kubelet[36342]: I0402 00:48:20.415277   36342 kuberuntime_manager.go:1523] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Apr 02 00:48:20 minikube kubelet[36342]: I0402 00:48:20.416123   36342 kubelet_network.go:61] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Apr 02 00:49:00 minikube kubelet[36342]: E0402 00:49:00.205034   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:49:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:49:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:49:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:50:00 minikube kubelet[36342]: E0402 00:50:00.208343   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:50:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:50:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:50:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:51:00 minikube kubelet[36342]: E0402 00:51:00.205104   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:51:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:51:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:51:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:52:00 minikube kubelet[36342]: E0402 00:52:00.204057   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:52:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:52:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:52:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:53:00 minikube kubelet[36342]: W0402 00:53:00.198263   36342 machine.go:65] Cannot read vendor id correctly, set empty.
Apr 02 00:53:00 minikube kubelet[36342]: E0402 00:53:00.203213   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:53:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:53:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:53:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:54:00 minikube kubelet[36342]: E0402 00:54:00.206046   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:54:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:54:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:54:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:55:00 minikube kubelet[36342]: E0402 00:55:00.204669   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:55:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:55:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:55:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:56:00 minikube kubelet[36342]: E0402 00:56:00.205168   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:56:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:56:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:56:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:57:00 minikube kubelet[36342]: E0402 00:57:00.206981   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:57:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:57:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:57:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:58:00 minikube kubelet[36342]: W0402 00:58:00.197147   36342 machine.go:65] Cannot read vendor id correctly, set empty.
Apr 02 00:58:00 minikube kubelet[36342]: E0402 00:58:00.205738   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:58:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:58:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:58:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"
Apr 02 00:59:00 minikube kubelet[36342]: E0402 00:59:00.204149   36342 iptables.go:575] "Could not set up iptables canary" err=<
Apr 02 00:59:00 minikube kubelet[36342]:         error creating chain "KUBE-KUBELET-CANARY": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Apr 02 00:59:00 minikube kubelet[36342]:         Perhaps ip6tables or your kernel needs to be upgraded.
Apr 02 00:59:00 minikube kubelet[36342]:  > table="nat" chain="KUBE-KUBELET-CANARY"

* 
* ==> storage-provisioner [a0c980560e33] <==
* I0402 00:48:13.834205       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0402 00:48:13.841151       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0402 00:48:13.841266       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0402 00:48:13.845377       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0402 00:48:13.845569       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"e8d05bc1-0dd4-4101-a433-410b6abcf6c4", APIVersion:"v1", ResourceVersion:"401", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_373baf0b-13c4-47e8-b1af-4448b6308800 became leader
I0402 00:48:13.845600       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_373baf0b-13c4-47e8-b1af-4448b6308800!
I0402 00:48:13.945873       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_373baf0b-13c4-47e8-b1af-4448b6308800!

